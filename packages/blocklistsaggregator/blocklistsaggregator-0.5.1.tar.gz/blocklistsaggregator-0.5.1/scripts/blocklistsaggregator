#!/usr/bin/env python

# Copyright (C) 2016 Pier Carlo Chiodi
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import argparse
import json
import logging
from logging.config import fileConfig
import os.path

from netaddr import IPNetwork

from pierky.blocklistsaggregator.lists import BlockLists, get_bl_from_id
from pierky.blocklistsaggregator.formatters import Formatters, \
                                                   get_formatter_from_id
from pierky.blocklistsaggregator.version import __version__, COPYRIGHT_YEAR

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger()


def validate_prefix(prefix):
    try:
        ip = IPNetwork(prefix)
        return ip
    except:
        raise argparse.ArgumentTypeError(
            "Invalid IP prefix: {}".format(prefix)
        )


def add_prefix(args, ipnetwork_or_string, bl_ids, entries):
    try:
        if ipnetwork_or_string is IPNetwork:
            prefix = ipnetwork_or_string
        else:
            prefix = IPNetwork(ipnetwork_or_string)

        if str(prefix) in entries["unique"]:
            if isinstance(bl_ids, list):
                entries["unique"][str(prefix)]["bl_ids"].update(bl_ids)
            else:
                entries["unique"][str(prefix)]["bl_ids"].add(bl_ids)
            return "duplicate"

        if prefix.version == 4 and args.v6_only:
            return "filtered"
        if prefix.version == 6 and args.v4_only:
            return "filtered"

        if args.only_global_unicast_addresses:
            if not prefix.is_unicast() or prefix.is_private():
                return "filtered"

        if prefix.version == 4:
            if prefix.prefixlen < args.exclude_ipv4_shorter_than:
                return "filtered"
        elif prefix.version == 6:
            if prefix.prefixlen < args.exclude_ipv6_shorter_than:
                return "filtered"

        for excluded_prefix in args.exclude:
            if prefix in excluded_prefix or prefix == excluded_prefix:
                return "filtered"

        entries["v{}".format(prefix.version)].append(prefix)
        entries["unique"][str(prefix)] = {
            "bl_ids": set()
        }
        if isinstance(bl_ids, list):
            entries["unique"][str(prefix)]["bl_ids"] = set(bl_ids)
        else:
            entries["unique"][str(prefix)]["bl_ids"].add(bl_ids)
    except Exception as e:
        logger.info("Error processing entry '{}', skipping it - {}".format(
            str(e), ipnetwork_or_string
        ))
        return "error"

    return "ok"


def main():
    parser = argparse.ArgumentParser(
        description="IP Block Lists Aggregator v{}".format(__version__),
        epilog="Copyright (c) {} - Pier Carlo Chiodi - "
               "https://pierky.com".format(COPYRIGHT_YEAR))

    parser.add_argument(
        "-i", "--input",
        help="JSON file to read entries from (instead of fetching them "
             "from online block lists feeds). Use '-' to read from stdin.",
        type=argparse.FileType("r")
    )

    parser.add_argument(
        "-o", "--output",
        help="Output file. Default: '-' (stdout).",
        type=argparse.FileType("w"),
        default="-"
    )

    output_formats = []
    for formatter_class in Formatters:
        output_formats.append(formatter_class.ID)

    parser.add_argument(
        "-f", "--output-format",
        help="Output format. Default: 'lines'.",
        choices=output_formats,
        default="lines"
    )

    parser.add_argument(
        "--logging-config-file",
        help="Logging configuration file, in Python fileConfig() format ("
             "https://docs.python.org/2/library/logging.config.html"
             "#configuration-file-format)"
    )

    parser.add_argument(
        "--lists-storage-dir",
        help="Save parsed lists into the DIR directory.",
        metavar="DIR"
    )
    parser.add_argument(
        "--recover-from-file",
        help="In case of failure while processing new lists load entries "
             "from previously saved files. Requires --lists-storage-dir.",
        action="store_true"
    )

    # ----------------------------------------
    group = parser.add_argument_group(
        title="Source lists"
    )

    list_ids = [bl_class.ID for bl_class in BlockLists]
    use_by_default_list_ids = [bl_class.ID
                               for bl_class in BlockLists
                               if bl_class.USE_BY_DEFAULT]
    group.add_argument(
        "--lists",
        help="Block lists to use. One or more of the following: {}. "
             "Default: all except {}.".format(
                 ", ".join(list_ids),
                 ", ".join([bl_id
                            for bl_id in list_ids
                            if bl_id not in use_by_default_list_ids])
            ),
        nargs="*",
        choices=list_ids,
        default=use_by_default_list_ids,
        dest="lists",
        metavar="LIST_ID"
    )

    group.add_argument(
        "--lists-include",
        help="Add the given LIST_ID to the block lists set "
             "expected for --lists.",
        nargs="*",
        choices=list_ids,
        dest="lists_include",
        metavar="LIST_ID"
    )

    group.add_argument(
        "--lists-exclude",
        help="Remove the given LIST_ID from the block lists set "
             "expected for --lists.",
        nargs="*",
        choices=list_ids,
        dest="lists_exclude",
        metavar="LIST_ID"
    )

    # ----------------------------------------
    group = parser.add_argument_group(
        title="Filters"
    )

    group.add_argument(
        "-4", "--ipv4-only",
        help="Only IPv4 entries will be processed.",
        action="store_true",
        dest="v4_only"
    )

    group.add_argument(
        "-6", "--ipv6-only",
        help="Only IPv6 entries will be processed.",
        action="store_true",
        dest="v6_only"
    )

    group.add_argument(
        "--exclude-ipv4-shorter-than",
        help="Exclude IPv4 prefixes whose length is shorter than X. "
             "Default: 0.",
        default=0,
        type=int,
        metavar="X"
    )

    group.add_argument(
        "--exclude-ipv6-shorter-than",
        help="Exclude IPv6 prefixes whose length is shorter than X. "
             "Default: 0.",
        default=0,
        type=int,
        metavar="X"
    )

    group.add_argument(
        "--exclude",
        help="Exclude block list entries whose prefix falls whithin one of "
             "the prefixes that are listed here. Default: FE80::/10.",
        nargs="*",
        default=[IPNetwork("FE80::/10")],
        type=validate_prefix
    )

    group.add_argument(
        "--only-global-unicast-addresses",
        help="Exclude any IP address/prefix that is not unicast and global. "
             "Default: False.",
        action="store_true",
        default=False
    )

    for formatter_class in Formatters:
        formatter_class.add_args(parser)

    args = parser.parse_args()

    if args.logging_config_file:
        try:
            fileConfig(args.logging_config_file)
        except Exception as e:
            logger.error(
                "Error processing the --logging-config-file - {}".format(
                    str(e)
                )
            )
            return

    if args.lists_storage_dir:
        if not os.path.isdir(args.lists_storage_dir):
            logger.error(
                "The directory {} does not exist.".format(
                    args.lists_storage_dir
                )
            )
            return

    if args.recover_from_file:
        if not args.lists_storage_dir:
            logger.error(
                "The --recover-from-file argument requires the "
                "--lists-storage-dir."
            )
            return

    formatter_class = get_formatter_from_id(args.output_format)
    formatter = formatter_class(args)

    if not formatter.init():
        return

    lists = args.lists

    if args.lists_include:
        for bl_id in args.lists_include:
            if bl_id not in lists:
                lists.append(bl_id)

    if args.lists_exclude:
        for bl_id in args.lists_exclude:
            if bl_id in lists:
                lists.remove(bl_id)

    if not lists:
        logger.error("The given --lists, --lists-include and --lists-exclude "
                     "argumets result into an empty set of block lists.")
        return

    # v4 and v6: lists of IPNetwork() objects
    # unique:    dict of string representation of the same prefixes which are
    #            added to v4 and v6; used to speed up the lookup that avoids
    #            duplicated entries in add_prefix()
    #            format:
    #               "<prefix">: { "bl_ids": set("<bl_id_1>", "<bl_id_N>") }
    entries = {
        "v4": [],
        "v6": [],
        "unique": {}
    }

    stats = {
        "ok": 0,
        "duplicate": 0,
        "filtered": 0,
        "error": 0
    }

    if args.input:
        logger.info("Reading entries from input file...")

        try:
            from_file = json.loads(args.input.read())
        except Exception as e:
            logger.error("Error while loading input file - {}".format(str(e)))
            return

        logger.info("Processing entries...")

        for v4v6 in (4, 6):
            for entry in from_file["v{}".format(v4v6)]:
                bl_ids = from_file["v{}".format(v4v6)][entry]["bl_ids"]
                stats[add_prefix(args, entry, bl_ids, entries)] += 1
    else:
        for bl_class_id in lists:
            blocklist_class = get_bl_from_id(bl_class_id)

            logger.info("Downloading and parsing {}...".format(
                blocklist_class.NAME
            ))

            bl = blocklist_class()

            try:
                bl.load()
                if args.lists_storage_dir:
                    path = os.path.join(args.lists_storage_dir, bl_class_id)
                    try:
                        bl.save_to_file(path)
                    except Exception as e:
                        logger.warning(
                            "Error while saving {} into {} - {}".format(
                                bl.NAME, path, str(e)
                            )
                        )
            except Exception as e:
                path = None
                if args.recover_from_file:
                    path = os.path.join(args.lists_storage_dir, bl_class_id)
                if path and os.path.isfile(path):
                    logger.warning(
                        "Error while processing {} - {} - "
                        "recovering from file {}".format(
                            bl.NAME, str(e), path
                        )
                    )
                    try:
                        bl.load_from_file(path)
                    except Exception as e:
                        logger.warning(
                            "Error while recovering {} from "
                            "file {} - {} - skipping it".format(
                                bl.NAME, path, str(e)
                            )
                        )
                else:
                    logger.warning(
                        "Error while processing {} - {} - "
                        "skipping it".format(
                            bl.NAME, str(e)
                        )
                    )

            for prefix in bl.entries:
                stats[add_prefix(args, prefix, bl_class_id, entries)] += 1

    logger.info(
        "Stats: {} ok, {} duplicate, {} filtered, {} errors - "
        "total: {} entries".format(
            stats["ok"], stats["duplicate"], stats["filtered"], stats["error"],
            stats["ok"] + stats["duplicate"] + stats["filtered"] + \
                stats["error"]
        )
    )
    if stats["error"] > 0:
        logger.warning("Can't process one or more block list entries")

    try:
        formatter.emit(entries, args.output)
    except Exception as e:
        logger.error("Error while writing output ('{}') - {}".format(
            args.output_format, str(e)
        ))
        return

main()
