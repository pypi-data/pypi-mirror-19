#!/usr/bin/env python

import argparse
from copy import deepcopy
import datetime
import json
import logging
from logging.handlers import RotatingFileHandler
import os.path
import select
try:
    from Queue import Queue, Empty
except:
    from queue import Queue, Empty
import sys


from pierky.p2es.es import *
from pierky.p2es.transformations import *
from pierky.p2es.version import __version__ 
from pierky.p2es.workers import *

APP_NAME = 'pmacct-to-elasticsearch'
CURRENT_RELEASE = 'v{}'.format(__version__)

CONF_DIR = '/etc/p2es'

DEF_CONFIG = {
    'CONF_DIR': CONF_DIR,

    'LogFile': '/var/log/{}-$PluginName.log'.format(APP_NAME),

    'ES_URL': 'http://localhost:9200',
    'ES_IndexName': '',
    'ES_Type': '',
    'ES_AuthType': 'none',

    'ES_FlushSize': 5000,
    
    'ReaderThreads': 2,
    'InputFormat': 'json',

    'InputFile': None,

    'Transformations': []
}

CONFIG = DEF_CONFIG.copy()


def expand_macros(s):
    if s is None:
        return None
    
    out = deepcopy(s)
    out = out.replace('$PluginName', CONFIG.get('PluginName') or 'default')
    out = out.replace('$IndexName', datetime.datetime.now().strftime(
        CONFIG.get('ES_IndexName') or 'default'
    ))
    out = out.replace('$Type', CONFIG.get('ES_Type') or 'default')
    return out

# Checks config and logs any errors.
# Returns: True | False.
# Raises exceptions: no
def check_config():
    if not CONFIG['ES_IndexName']:
        log(logging.ERROR, 'ElasticSearch index name not provided')
        return False

    if not CONFIG['ES_Type']:
        log(logging.ERROR, 'ElasticSearch type not provided')
        return False

    if not CONFIG['ES_URL']:
        log(logging.ERROR, 'ElasticSearch URL not provided')
        return False

    if not 'ES_IndexTemplateFileName' in CONFIG:
        CONFIG['ES_IndexTemplateFileName'] = 'new-index-template.json'
    else:
        index_tpl_path = '{}/{}'.format(
            CONF_DIR, CONFIG['ES_IndexTemplateFileName']
        )

        if not os.path.isfile(index_tpl_path):
            log(logging.ERROR,
                'Can\'t find index template file {}'.format(index_tpl_path))
            return False
        else:
            with open(index_tpl_path, "r") as f:
                try:
                    index_tpl = json.load(f)
                except Exception as e:
                    log(logging.ERROR,
                        'Index template from {} is not '
                        'in valid JSON format: {}'.format(
                            index_tpl_path, str(e)
                        ),
                        exc_info=True)
                    return False

    if CONFIG['ES_URL'].endswith('/'):
        CONFIG['ES_URL'] = CONFIG['ES_URL'][:-1]

    if CONFIG['ES_AuthType']:
        if not CONFIG['ES_AuthType'] in ('none', 'basic', 'digest'):
            log(logging.ERROR,
                'Authentication type must be "none" (default), '
                '"basic" or "digest"')
            return False

    if CONFIG['ES_AuthType'] in ('basic', 'digest'):
        if not CONFIG['ES_UserName']:
            log(logging.ERROR,
                'Authentication required but username not provided')
            return False

        if not CONFIG['ES_Password']:
            log(logging.ERROR, 'Authentication required but password not provided')
            return False

    if not 'ES_FlushSize' in CONFIG:
        log(logging.ERROR, 'Flush size not provided')
        return False
    else:
        try:
            CONFIG['ES_FlushSize'] = int(CONFIG['ES_FlushSize'])
        except:
            log(logging.ERROR, 'Flush size must be a positive integer')
            return False

        if CONFIG['ES_FlushSize'] < 0:
            log(logging.ERROR, 'Flush size must be a positive integer')
            return False

    if not 'ReaderThreads' in CONFIG:
        log(logging.ERROR, 'Reader threads number not provided')
        return False

    if isinstance(CONFIG['ReaderThreads'], str) and \
        not CONFIG['ReaderThreads'].isdigit():
        log(logging.ERROR, 'Reader threads number must be a positive integer')
        return False

    CONFIG['ReaderThreads'] = int(CONFIG['ReaderThreads'])
    if CONFIG['ReaderThreads'] <= 0:
        log(logging.ERROR, 'Reader threads number must be a positive integer')
        return False

    if not 'InputFormat' in CONFIG:
        log(logging.ERROR, 'Input format not provided')
        return False

    valid_input_formats = ('json', 'csv')
    if CONFIG['InputFormat'] not in valid_input_formats:
        log(logging.ERROR,
            'Unknown input format "{}": must be one of {}'.format(
                CONFIG['InputFormat'], ", ".join(valid_input_formats)
            )
        )
        return False

    if 'Transformations' in CONFIG:
        for tr in CONFIG['Transformations']:
            try:
                test_transformation(tr)
            except P2ESError as e:
                log(logging.ERROR,
                    'Invalid transformation: {}'.format(str(e)))
                return False

    return True

# Setup logging to stdout (is possible), file or stderr.
# Returns: True | False.
# Raises exceptions: no.
def setup_logging(baselogfile=None):
    if baselogfile:
        logfilepath = expand_macros(baselogfile)
    else:
        logfilepath = None

    logger = logging.getLogger(APP_NAME)
    formatter = logging.Formatter("%(asctime)s %(levelname)s %(message)s")
    logger.setLevel(logging.INFO)

    logger.handlers = []

    if logfilepath:
        # log to stdout too
        if sys.stdout.isatty():
            try:
                hdlr = logging.StreamHandler(sys.stdout)
                hdlr.setFormatter(formatter)
                logger.addHandler(hdlr)
            except:
                pass
        try:
            hdlr = logging.handlers.RotatingFileHandler(logfilepath,
                                                        maxBytes=1000000,
                                                        backupCount=3)
            hdlr.setFormatter(formatter)
            logger.addHandler(hdlr)
        except:
            log(logging.ERROR,
                "Can't setup logging to file {}. "
                "Ensure it has write permissions for the current user.".format(
                    logfilepath
                )
            )
            return False
    else:
        try:
            hdlr = logging.StreamHandler(sys.stderr)
            hdlr.setFormatter(formatter)
            logger.addHandler(hdlr)
        except:
	    sys.stderr.write("Can't setup logging to stderr.")
            return False

    return True

def log(lev, msg, exc_info=False):
    logger = logging.getLogger(APP_NAME)
    logger.log(lev, msg, exc_info=exc_info)

def main():
    parser = argparse.ArgumentParser(
        description="pmacct-to-elasticsearch {}: a tool to read "
                    "pmacct's output and to store it into "
                    "ElasticSearch.".format(CURRENT_RELEASE),
        epilog="Copyright (c) {} - Pier Carlo Chiodi - "
               "https://pierky.com".format(2017)
    )
    parser.add_argument(
        "pluginname",
        help="Plugin name.")
    parser.add_argument(
        "-p", "--print",
        help="Only print output to stdout "
             "(does not send data to ElasticSearch).",
        action="store_true",
        dest="print_only")
    parser.add_argument(
        "-t", "--test",
        help="Only tests configuration "
             "(does not send data to ElasticSearch).",
        action="store_true",
        dest="test_only")
    parser.add_argument(
        "--test-condition",
        help="Test conditions given in FILE against --test-condition-data.",
        metavar="FILE",
        dest="test_condition")
    parser.add_argument(
        "--test-condition-data",
        help="Data used to test condition given in --test-condition.",
        metavar="FILE",
        dest="test_condition_data")

    args = parser.parse_args()

    if not setup_logging():
        return False

    if args.test_condition and args.test_condition_data:
        with open(args.test_condition, "r") as f:
            c = json.load(f)
        with open(args.test_condition_data, "r") as f:
            d = json.load(f)
        print(
            "Tested condition evaluated to {}".format(
                parse_conditions(c, d)
            )
        )
        return True
    else:
        if args.test_condition and not args.test_condition_data or \
            args.test_condition_data and not args.test_condition:
            log(logging.ERROR, "--test-condition and --test-condition-data "
                "must be used togheter.")
            return False

    CONFIG["PluginName"] = args.pluginname

    # Loading configuration
    new_cfg_file_name = "{}.conf".format(CONFIG["PluginName"])
    try:
        with open('{}/{}'.format(CONF_DIR, new_cfg_file_name), "r") as f:
            new_cfg = json.load(f)
    except:
        log(logging.ERROR,
            'Error loading configuration from {}/{}'.format(
                CONF_DIR, new_cfg_file_name),
            exc_info=True)
        return False

    CONFIG.update(new_cfg)

    if 'LogFile' in CONFIG:
        if not setup_logging(CONFIG['LogFile']):
            return False
    else:
        log(logging.ERROR, 'Missing LogFile')
        return False

    if not check_config():
        return False

    if args.test_only:
        print('Configuration tested successfully')
        return True
    
    if not CONFIG['InputFile']:
        r, w, x = select.select([sys.stdin], [], [], 0)
        if not r:
            log(logging.ERROR, 'Error while reading input data from stdin')
            return False
    
    # Timestamp for ES indexing (UTC)

    ts = datetime.datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')

    # Read pmacct's output and perform transformations

    writer_queue = Queue()
    errors_queue = Queue()

    if args.print_only:
        writer_thread_class = PrintOnlyWriterThread
    else:
        writer_thread_class = ESWriterThread

    try:
        writer = writer_thread_class("writer",
                                     CONFIG,
                                     errors_queue,
                                     ts,
                                     writer_queue,
                                     CONFIG['ES_FlushSize'])
        writer.daemon = True
        writer.start()
    except P2ESError as e:
        log(logging.ERROR, str(e))
        return False

    try:
        if CONFIG['InputFormat'] == 'json':
            reader_class = JSONReader
        elif CONFIG['InputFormat'] == 'csv':
            reader_class = CSVReader

        reader = reader_class(
            CONFIG,
            expand_macros(CONFIG['InputFile']) if CONFIG['InputFile'] else None,
            errors_queue,
            writer_queue
        )
    except P2ESError as e:
        log(logging.ERROR, str(e))
        return False

    ret_code = True
    try:
        reader.process_input()
    except Exception as e:
        log(logging.ERROR,
            "Error while processing input: {}".format(str(e)))
        ret_code = False
    finally:
        reader.finalize()

    writer.queue.put(None)
    writer.join()

    while True:
        try:
            err = errors_queue.get(block=False)
            ret_code = False
            log(logging.ERROR, err)
        except Empty:
            break

    return ret_code

main()
