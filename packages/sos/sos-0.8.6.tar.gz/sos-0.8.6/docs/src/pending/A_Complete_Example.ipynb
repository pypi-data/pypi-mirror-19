{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A RNA Seq data processing workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are curious about how to write large workflows using SoS or just how a long SoS script looks like, here is a RNA Seq data processing workflow written in SoS. The workflow consists of many steps and was written in a mixed style, namely a spine of forward-moving steps and several auxiliary steps that supply required information. The DAG of the workflow looks like\n",
    " \n",
    "![DAG](media/example_dag.png)\n",
    "\n",
    "although this DAG does not include many auxiliary steps (e.g. those that download required resources) because these steps were called once and would not be called once the resources are available. The DAG is generated using command\n",
    "\n",
    "```\n",
    "sos prepare RNASeq_hg10.sos\n",
    "cat .sos/human_hg19.dot | dot -T png > example_dag.png\n",
    "```\n",
    "\n",
    "This tutorial will divide the workflow into several parts and briefly describe each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Header\n",
    "\n",
    "The header of script contains description of the workflow.\n",
    "\n",
    "```\n",
    "#!/usr/bin/env sos-runner\n",
    "#fileformat=SOS1.0\n",
    "\n",
    "# Workflow for a comprehensive analysis of paired-end RNA seq data\n",
    "# that performs read-level quality assessment, alignment, alignment quality\n",
    "# assessment, summary statistics, fusion detection and filtering, gene and exon\n",
    "# level expression counts, and variant calling. The input of this pipeline\n",
    "# should be a list of fastq or fastq.gz files with paired reads differentiated\n",
    "# by _R1_ and _R2_ in filenames. <p>The output of the pipeline should be a\n",
    "# directory to which all results will be written. The directory will be \n",
    "# created if it does not exist. Note that it is highly recommended that\n",
    "# you execute the pipeline with a subset of samples (using option --sampling\n",
    "# 1000000) to test the pipeline before you apply it to the full dataset. \n",
    "# Network connection will be needed for the first run (to download resources)\n",
    "# but not for subsequent runs. For details of the pipeline including the\n",
    "# accepted parameters, please run command \"vtools show pipeline RNASeq_hg19_v3\".\n",
    "\n",
    "# human_hg19\n",
    "# \n",
    "# This pipeline uses the hg19 version of the reference\n",
    "# genome, genes downloaded from Illumina iGenome, and existing variants from\n",
    "# the GATK resource bundle. This pipeline uses <ul>\n",
    "#   <li>tophat 2.0.13 \n",
    "#   <li>bowtie 1.1.1\n",
    "#   <li>samtools 0.1.19\n",
    "#   <li>picard 1.82\n",
    "#   <li>GATK 3.3\n",
    "#   <li>fastqc 0.11.2\n",
    "#   <li>BEDTools 2.17.0\n",
    "#   <li>RSeQC 2.4, and\n",
    "#   <li>Oncofuse 1.0.7\n",
    "#   </ul>\n",
    "# Other versions of the tools can be used if you execute the pipeline with option\n",
    "# --strict_version False, but the pipeline might or might not work as expected. \n",
    "# Please download all these tools and make them available to the pipeline (set $PATH),\n",
    "# and start the pipeline using command \"vtools execute /path/to/this_file options\".\n",
    "# Noted that the precompiled version of tophat 2.0.13 can fail under mac so it is\n",
    "# recommended that you compile tophat2 from source.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inclusion of auxiliary steps\n",
    "\n",
    "```\n",
    "%from install_ngs include *\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global definitions\n",
    "\n",
    "```\n",
    "\n",
    "if os.path.isdir(os.path.expanduser('~/rsrch1/variant_tools_resource/pipeline_resource')):\n",
    "    resource_dir  = os.path.expanduser('~/rsrch1/variant_tools_resource/pipeline_resource')\n",
    "elif os.path.isdir(os.path.expanduser('~/.variant_tools/pipeline_resource')):\n",
    "    resource_dir  = os.path.expanduser('~/.variant_tools/pipeline_resource')\n",
    "else:\n",
    "    fail_if(True, 'Unable to locate a resource directory')\n",
    "\n",
    "# Path to picard jar files\n",
    "parameter: picard_path = '~/bin/Picard'\n",
    "\n",
    "# Path to GenomeAnalysisTK.jar\n",
    "parameter: gatk_path = '~/bin/GATK'\n",
    "\n",
    "# Path to Oncofuse.jar\n",
    "parameter: oncofuse_path = '~/bin/Oncofuse'\n",
    "\n",
    "# input fastq files\n",
    "parameter: fastq_files = list\n",
    "\n",
    "fail_if(len([x for x in fastq_files if '_R1_' in x]) == 0  \\\n",
    "    or len([x for x in fastq_files if '_R1_' in x]) != len([x for x in fastq_files if '_R2_' in x]),\n",
    "    'Input file names are not paired fastq files differentiated by _R1_ and _R2_ in filename.')\n",
    "\n",
    "# Name of the sample being processed, which will be used for filename\n",
    "# and read group of aligned reads.\n",
    "parameter: samplename = str\n",
    "\n",
    "# If set to a positive number, this pipeline will sample specified\n",
    "# number of reads (pairs) from the input. This is useful to test if the pipeline\n",
    "# works for your environment, download all needed resources, created indexes,\n",
    "# and check the quality of data.\n",
    "parameter: sampling = 0\n",
    "\n",
    "\n",
    "# An optional filename that contains detailed information\n",
    "# about the sample. The sample sheet should be a tab or comma-delimited \n",
    "# file with a header, and one or more lines with one of which contain the \n",
    "# information of the sample. The information from the sample sheet will be\n",
    "# written to the final report (summary.html).\n",
    "parameter: sample_sheet = ''\n",
    "\n",
    "#\n",
    "# CONSTANT VALUES: not configurable in this pipeline\n",
    "# \n",
    "pipeline_name     = 'RNASeq_hg19'\n",
    "pipeline_version  = 'ver1.0 (2016/8/29'\n",
    "reference_genome  = 'hg19'\n",
    "reference_genes   = 'UCSC/Illumina iGenome'\n",
    "# HG19 version of the resource files\n",
    "gatk_resource_dir = '${resource_dir}/GATK/2.8/hg19/'\n",
    "igenome_resource_dir = '${resource_dir}/iGenome'\n",
    "ncbi_resource_dir = '${resource_dir}/NCBI'\n",
    "\n",
    "igenome_url       = 'ftp://igenome:G3nom3s4u@ussd-ftp.illumina.com/Homo_sapiens/UCSC/hg19/Homo_sapiens_UCSC_hg19.tar.gz'\n",
    "gene_info_url     = 'ftp://ftp.ncbi.nih.gov/gene/DATA/GENE_INFO/Mammalia/Homo_sapiens.gene_info.gz'\n",
    "reference_dir     = '${igenome_resource_dir}/Homo_sapiens/UCSC/hg19/Sequence'\n",
    "transcriptome_dir = '${igenome_resource_dir}/Homo_sapiens/UCSC/hg19/Annotation/transcriptome_index'\n",
    "annotation_dir    = '${igenome_resource_dir}/Homo_sapiens/UCSC/hg19/Annotation'\n",
    "refgene_txt       = '${annotation_dir}/Genes/refGene.txt'\n",
    "genes_gtf         = '${annotation_dir}/Genes/genes.gtf'\n",
    "# generated files'\n",
    "refgene_bed       = '${annotation_dir}/Genes/refGene.bed'\n",
    "genes_exon_bed    = '${annotation_dir}/Genes/genes_exon.bed'\n",
    "genes_with_chr_gtf= '${annotation_dir}/Genes/genes_chr.gtf'\n",
    "genesize_txt      = '${annotation_dir}/Genes/geneSize.txt'\n",
    "# Download from UCSC'\n",
    "ensgene_url       = 'http://hgdownload.cse.ucsc.edu/goldenpath/hg19/database/ensGene.txt.gz'\n",
    "ensgene_txt       = '${annotation_dir}/Genes/ensGene.txt'\n",
    "chromsize_url     = 'ftp://hgdownload.cse.ucsc.edu/goldenPath/hg19/database/chromInfo.txt.gz'\n",
    "chromsize_txt     = '${annotation_dir}/chromsize.txt'\n",
    "# GATK resource bundle'\n",
    "gatk_url          = 'ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/2.8/hg19/'\n",
    "# '\n",
    "# Output directories'\n",
    "output_dir        = samplename\n",
    "temp_dir          = '${output_dir}/tmp'\n",
    "alignment_out     = '${output_dir}/alignment'\n",
    "alignmentqc_out   = '${output_dir}/alignment_qc'\n",
    "fusion_out        = '${output_dir}/fusion'\n",
    "readqc_out        = '${output_dir}/read_qc'\n",
    "count_out         = '${output_dir}/counts'\n",
    "variant_out       = '${output_dir}/variants'\n",
    "\n",
    "\n",
    "\n",
    "[human_hg19_100: skip=sampling == 0, shared='fastq_files']\n",
    "# Select a subset of reads if parameter --sampling is specified. Output will be \n",
    "# written to the project cache directory.\n",
    "input:\n",
    "    fastq_files\n",
    "\n",
    "depends:\n",
    "    executable('gunzip')\n",
    "\n",
    "output:\n",
    "    '${temp_dir}/${samplename}_R1_${sampling}.fastq',\n",
    "    '${temp_dir}/${samplename}_R2_${sampling}.fastq'\n",
    "\n",
    "run:\n",
    "    gunzip -c ${' '.join(sorted([x for x in input if '_R1_' in x]))} | head -n ${4*sampling} > ${output[0]}\n",
    "    gunzip -c ${' '.join(sorted([x for x in input if '_R2_' in x]))} | head -n ${4*sampling} > ${output[1]}\n",
    "\n",
    "fastq_files = output\n",
    "\n",
    "\n",
    "[human_hg19_110]\n",
    "# Use fastqc to check the quality of input reads\n",
    "#\n",
    "input:\n",
    "    fastq_files\n",
    "\n",
    "depends:\n",
    "    executable('fastqc'),\n",
    "    executable('gunzip')\n",
    "\n",
    "output:\n",
    "    '${readqc_out}/${samplename}_fastqc.html',\n",
    "    '${readqc_out}/${samplename}_fastqc.zip'\n",
    "\n",
    "task:\n",
    "\n",
    "run:\n",
    "    # the input can be original .fast.gz file or extracted \n",
    "    ${\"gunzip -c\" if input[0].endswith(\".gz\") else \"cat\"} ${input} | fastqc stdin --outdir=${readqc_out}\n",
    "    mv ${readqc_out}/stdin_fastqc.html  ${output[0]}\n",
    "    mv ${readqc_out}/stdin_fastqc.zip ${output[1]}\n",
    "\n",
    "[extract_fastqc_figures: provides=[os.path.join(readqc_out, x) for x in ('per_base_quality.png', 'per_sequence_gc_content.png', 'per_base_sequence_content.png')]]\n",
    "input:\n",
    "    '${readqc_out}/${samplename}_fastqc.zip'\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "with zipfile.ZipFile(input[0]) as qczip:\n",
    "    for name in qczip.namelist():\n",
    "        if os.path.basename(name) in ['per_base_quality.png', 'per_sequence_gc_content.png', 'per_base_sequence_content.png']:\n",
    "            qczip.extract(name, readqc_out)\n",
    "            # move the file to top directory\n",
    "            os.rename(os.path.join(readqc_out, name), os.path.join(readqc_out, os.path.basename(name)))\n",
    "\n",
    "\n",
    "[download_ensgene: provides=genes_gtf]\n",
    "download:  '${annotation_dir}/Genes/'\n",
    "    ${ensgene_url}\n",
    "\n",
    "[chr_gtf: provides = genes_with_chr_gtf]\n",
    "# takes gtf and and chromosome names to gene name to avoid problems\n",
    "# with genes with the same names on different chromosomes\n",
    "input:\n",
    "    genes_gtf\n",
    "\n",
    "output:\n",
    "    genes_with_chr_gtf\n",
    "\n",
    "python:\n",
    "    #\n",
    "    #    Input format:\n",
    "    #\n",
    "    #        chr1 unknown exon 17233 17368 . - . gene_id \"WASH7P\"; gene_name \"WASH7P\"; transcript_id \"NR_024540\"; tss_id \"TSS8151\";\n",
    "    #\n",
    "    #    Output format:\n",
    "    #           chr1 unknown exon 17233 17368 . - . gene_id \"WASH7P\"; gene_name \"WASH7P.chr1\"; transcript_id \"NR_024540\"; tss_id \"TSS8151\";\n",
    "    # \n",
    "    import re\n",
    "    pattern = re.compile(r'''(gene_id\\s+['\"]*)([\\w.-]+)''')\n",
    "    # only work on selected chromosomes\n",
    "    allowed_chromosomes = set([str(x) for x in range(25)] + ['chr{}'.format(x) for x in range(25)] + \\\n",
    "                ['X', 'Y', 'M', 'chrX', 'chrY', 'chrM'])\n",
    "    with open(input[0], 'rU') as ifile, open(output[0], 'w') as ofile:\n",
    "       for line in ifile:\n",
    "           if line.startswith('#'):\n",
    "               continue\n",
    "           ls = line.strip().split('\\t')\n",
    "           if ls[0] not in allowed_chromosomes:\n",
    "               continue\n",
    "           ofile.write(re.sub(pattern, r'\\1\\2.{}'.format(ls[0]), line)) \n",
    "\n",
    "[download_igenome: provides=refgene_bed]\n",
    "download: dest_dir=igenome_resource_dir\n",
    "    ${igenome_url}\n",
    "\n",
    "[human_hg19_400: shared={'param': 'output[0]'}]\n",
    "#\n",
    "# Align a subset of reads to obtain two key parameters parameters\n",
    "# --mate-inner-dist and --mate-std-dev for full scale alignment\n",
    "#\n",
    "input:\n",
    "    fastq_files\n",
    "\n",
    "depends:\n",
    "    genes_with_chr_gtf,\n",
    "    refgene_bed,\n",
    "    executable('tophat2'),\n",
    "    executable('bowtie'),\n",
    "    executable('inner_distance.py')\n",
    "    \n",
    "output:\n",
    "    '${temp_dir}/${samplename}.inner_distance_freq.txt'\n",
    "\n",
    "test_files = '${temp_dir}/${samplename}_R1_test.fastq', '${temp_dir}/${samplename}_R2_test.fastq'\n",
    "\n",
    "task:\n",
    "\n",
    "run:\n",
    "    ${'gunzip -c' if input[0].endswith('.gz') else 'cat'}  ${' '.join(sorted([x for x in input if '_R1_' in x]))} \\\n",
    "        | head -n 40000 > ${test_files[0]}\n",
    "\n",
    "    ${'gunzip -c' if input[0].endswith('.gz') else 'cat'}  ${' '.join(sorted([x for x in input if '_R2_' in x]))} \\\n",
    "        | head -n 40000 > ${test_files[1]}\n",
    "\n",
    "run:\n",
    "    tophat2 --zpacker 0 -no-coverage-search --library-type fr-unstranded \\\n",
    "        --max-multihits 20 --prefilter-multihits --num-threads 8 \\\n",
    "        --GTF ${genes_with_chr_gtf} --segment-length 25 \\\n",
    "        --transcriptome-index ${transcriptome_dir}/genes --bowtie1 \\\n",
    "        --output-dir ${temp_dir} ${reference_dir}/BowtieIndex/genome \\\n",
    "        ${test_files[0]} ${test_files[1]}\n",
    "\n",
    "run:\n",
    "    inner_distance.py -r ${refgene_bed} -i ${temp_dir}/accepted_hits.bam -o ${temp_dir}/${samplename}\n",
    "\n",
    "\n",
    "[human_hg19_440: shared={'accepted_hits':'output[0]', 'mate_inner_dist':'mate_inner_dist', 'mate_std_dev':'mate_std_dev'}]\n",
    "#Alignment (Tophat2): Running tophat2 with fusion search.\n",
    "#Alignment Preparation: Calculate mean and standard devision of inner distance and set parameters\n",
    "# --mate-inner-dist and --mate-std-dev\n",
    "import math\n",
    "values = []\n",
    "with open(param) as freq:\n",
    "    for line in freq:\n",
    "        s, e, c = [int(x) for x in line.split()]\n",
    "        values.extend([int(s+e)/2.] * c)\n",
    "if not values:\n",
    "    # no mapped reads...\n",
    "    mate_inner_dist = 50\n",
    "    mate_std_dev = 20\n",
    "    logger.info('Mean and standard deviation of inner distance is set to default values 50 and 20')\n",
    "else:\n",
    "    mean = sum(values)/len(values)\n",
    "    mean_sq = sum([x*x for x in values])/len(values)\n",
    "    sd = math.sqrt(mean_sq - mean*mean)\n",
    "    mate_inner_dist = int(mean)\n",
    "    mate_std_dev = int(sd)\n",
    "    logger.info('Mean and standard deviation of inner distance is set to {} and {}'.format(int(mean), int(sd)))\n",
    "\n",
    "input:\n",
    "    fastq_files\n",
    "\n",
    "depends:\n",
    "    genes_with_chr_gtf\n",
    "\n",
    "output:\n",
    "    '${alignment_out}/accepted_hits.bam'\n",
    "\n",
    "# use --zpacker 0 to disable compression of temporary file\n",
    "# which makes the program run faster\n",
    "run:\n",
    "    if [[ -f ${alignment_out}/logs/run.log ]] && [[ ! -f ${alignment_out}/accepted_hits.bam ]];  \\\n",
    "        then  \\\n",
    "        tophat2 --resume ${alignment_out} ||  \\\n",
    "        tophat2  \\\n",
    "        -no-coverage-search  \\\n",
    "        --library-type fr-unstranded  \\\n",
    "        --max-multihits 20  \\\n",
    "        --prefilter-multihits  \\\n",
    "        --num-threads 8  \\\n",
    "        --GTF ${genes_with_chr_gtf}  \\\n",
    "        --segment-length 25  \\\n",
    "        --keep-fasta-order  \\\n",
    "        --transcriptome-index ${transcriptome_dir}/genes  \\\n",
    "        --fusion-search --fusion-ignore-chromosomes chrM,M  \\\n",
    "        --fusion-min-dist 50000  \\\n",
    "        --bowtie1  \\\n",
    "        --mate-inner-dist ${mate_inner_dist}  \\\n",
    "        --mate-std-dev ${mate_std_dev}  \\\n",
    "        --output-dir ${alignment_out}  \\\n",
    "        ${reference_dir}/BowtieIndex/genome  \\\n",
    "        ${','.join(sorted([x for x in input if '_R1_' in x]))}  \\\n",
    "        ${','.join(sorted([x for x in input if '_R2_' in x]))}  \\\n",
    "        ;  \\\n",
    "    else   \\\n",
    "        tophat2  \\\n",
    "        -no-coverage-search  \\\n",
    "        --library-type fr-unstranded   \\\n",
    "        --max-multihits 20   \\\n",
    "        --prefilter-multihits  \\\n",
    "        --num-threads 8   \\\n",
    "        --GTF ${genes_with_chr_gtf}  \\\n",
    "        --segment-length 25   \\\n",
    "        --keep-fasta-order   \\\n",
    "        --transcriptome-index ${transcriptome_dir}/genes  \\\n",
    "        --fusion-search --fusion-ignore-chromosomes chrM,M   \\\n",
    "        --fusion-min-dist 50000  \\\n",
    "        --bowtie1   \\\n",
    "        --mate-inner-dist ${mate_inner_dist}  \\\n",
    "        --mate-std-dev ${mate_std_dev}  \\\n",
    "        --output-dir ${alignment_out}  \\\n",
    "        ${reference_dir}/BowtieIndex/genome  \\\n",
    "        ${','.join(sorted([x for x in input if '_R1_' in x]))}  \\\n",
    "        ${','.join(sorted([x for x in input if '_R2_' in x]))};  \\\n",
    "        fi \n",
    "\n",
    " \n",
    "[index_bam: provides='{filename}.bam.bai']\n",
    "# Index generated bam file\n",
    "input:\n",
    "    '${filename}.bam'\n",
    "\n",
    "run:\n",
    "    samtools index ${input}\n",
    "\n",
    "\n",
    "[human_hg19_460]\n",
    "# Add ReadGroup information to sorted bam file.\n",
    "\n",
    "# Read group identifier, which should be an unique identifier for each\n",
    "# instrument run (e.g. flowcell number + lane name + number). The filename before\n",
    "# the '_R1_' part will be used if this option is left unspecified.\n",
    "parameter: rgid = 'NA'\n",
    "warn_if(rgid == 'NA',\n",
    "    'A default (NA) value is used for parameter --rgid (intrument run ID)')\n",
    "\n",
    "# Platform/technology used to produce the read. Valid values include\n",
    "# ILLUMINA, SOLID, LS454, HELICOS and PACBIO\n",
    "parameter: rgpl = 'ILLUMINA'\n",
    "# check input parameters\n",
    "warn_if(not rgpl in ['ILLUMINA', 'SOLID', 'LS454', 'HELICOS', 'PACBIO'],\n",
    "    'PL (platform) value if not one of ILLUMINA, SOLID, LS454, HELICOS and PACBIO')\n",
    "\n",
    "# DNA preparation library identity.\n",
    "parameter: rglb = 'NA'\n",
    "warn_if(rglb == 'NA',\n",
    "    'A default (NA) value is used for parameter --rglb (library identification string)')\n",
    "#\n",
    "# Platform unit (e.g. barcode). This field is not used by GATK.\n",
    "parameter: rgpu = 'NA'\n",
    "warn_if(rgpu == 'NA',\n",
    "    'A default (NA) value is used for parameter --rgpu (platform unit, barcode)')\n",
    "\n",
    "\n",
    "input:\n",
    "     accepted_hits\n",
    "\n",
    "output:\n",
    "    '${temp_dir}/${samplename}-with_rg.bam'\n",
    "\n",
    "run:\n",
    "    java -Xmx16g -Xms512m   \\\n",
    "        -Djava.io.tmpdir=${temp_dir}   \\\n",
    "        -jar ${picard_path}/AddOrReplaceReadGroups.jar  \\\n",
    "        input=${input}  \\\n",
    "        OUTPUT=${temp_dir}/${samplename}-with_rg.bam  \\\n",
    "        VALIDATION_STRINGENCY=LENIENT  \\\n",
    "        RGID=${rgid}  \\\n",
    "        RGSM=${samplename}  \\\n",
    "        RGPL=ILLUMINA  \\\n",
    "        RGLB=${rglb}  \\\n",
    "        RGPU=${rgpu}  \\\n",
    "        RGCN=IPCT\n",
    "\n",
    "[human_hg19_470: shared={'sorted_unique':'output[0]'}]\n",
    "#Alignment: Remove fusion reads in preparation for variant calling.\n",
    "# step 475, samtools index is defined above\n",
    "output:\n",
    "    '${alignment_out}/${samplename}-sorted_uniq_nonF.bam'\n",
    "\n",
    "run:\n",
    "    samtools view -h ${input} \\\n",
    "        | awk -F '\\t' '{ if($0 ~ \"^@\") {print} else { for(i=12;i<=NF;i++){ if ($i ~ \"NH:i:1$\"){print}} } }' \\\n",
    "        | awk '{ if($0 ~ \"^@\") {print} else { if ($0 !~ \"XF:Z\") {print} }  }' \\\n",
    "        | samtools view -bS - > ${alignment_out}/${samplename}-sorted_uniq_nonF.bam\n",
    "\n",
    "\n",
    "[human_hg19_480]\n",
    "#Alignment: Count the number of junction reads. \n",
    "input:\n",
    "    accepted_hits\n",
    "\n",
    "output:\n",
    "    '${alignment_out}/junction.count'\n",
    "\n",
    "run:\n",
    "    samtools view -h ${input} \\\n",
    "   | awk '$6 ~/N/' | awk '{ if ($9 ~ /^-/) {print $1\"\\t-\"} else print $1\"\\t+\" }' \\\n",
    "   | sort -T ${temp_dir} -u | wc -l > ${alignment_out}/junction.count\n",
    "\n",
    "\n",
    "[human_hg19_500 (gene body coverage): shared={'rseqc_pdf':'output'}]\n",
    "# this version uses BAM files to count geneBody coverage, using .bw might be a more resource\n",
    "# saving idea but needs more testing, especially because the output of bigWig is currently normalized\n",
    "# and does not show the correct depth of coverage.\n",
    "input:\n",
    "    sorted_unique\n",
    "\n",
    "depends:\n",
    "    refgene_bed\n",
    "\n",
    "output:\n",
    "    '${alignmentqc_out}/${samplename}.geneBodyCoverage.curves.pdf'\n",
    "\n",
    "# this job can take a long time to execute so we tend to execute as a separate job\n",
    "task:\n",
    "run:\n",
    "    geneBody_coverage.py -r ${refgene_bed} -i ${input} -o ${alignmentqc_out}/${samplename}\n",
    "\n",
    "#[human_hg19_560]\n",
    "#RSeQC: Coverage of gene body\n",
    "#RunCommand('geneBody_coverage2.py -r ${refgene_bed} -i ${input551: input551[0][:-3] + \"bw\"} -t pdf -o ${alignmentqc_out}/${samplename}',\n",
    "#    output='${alignmentqc_out}/${samplename}.geneBodyCoverage.curves.pdf')\n",
    "\n",
    "[human_hg19_510]\n",
    "#RSeQC: Check if current sequencing depth is deep enough to perform alternative splicing analyses\n",
    "#RSeQC: Annotating splicing event and splicing junction.\n",
    "#RSeQC: Plot the distribution of inner distance between paired reads, which can be used to \n",
    "#   determine parameters --mate-inner-dist and --mate-std-dev of the pipeline.\n",
    "#RSeQC: read duplication plot\n",
    "#RSeQC: Read distribution (statistics)\n",
    "#RSeQC: Generate scaled wig track for depth\n",
    "input:\n",
    "    accepted_hits\n",
    "\n",
    "output:\n",
    "    '${alignmentqc_out}/${samplename}.junctionSaturation_plot.pdf',\n",
    "    '${alignmentqc_out}/${samplename}.splice_events.pdf',\n",
    "    '${alignmentqc_out}/${samplename}.splice_junction.pdf',\n",
    "    '${alignmentqc_out}/${samplename}.inner_distance_plot.pdf',\n",
    "    '${alignmentqc_out}//${samplename}.DupRate_plot.pdf',\n",
    "    '${alignmentqc_out}//${samplename}.read_distribution'\n",
    "\n",
    "task:\n",
    "run:\n",
    "    junction_saturation.py  -r ${refgene_bed} -i ${input} -o ${alignmentqc_out}/${samplename}\n",
    "    junction_annotation.py -r ${refgene_bed} -i ${input} -o ${alignmentqc_out}/${samplename}\n",
    "    inner_distance.py -r ${refgene_bed} -i ${input} -o ${alignmentqc_out}/${samplename}\n",
    "    read_duplication.py -i ${input} -o ${alignmentqc_out}/${samplename}\n",
    "    read_distribution.py -r ${refgene_bed} -i ${input} > ${alignmentqc_out}/${samplename}.read_distribution\n",
    "\n",
    "[human_hg19_600 (SortSam): shared={'sorted_bam':'output'}]\n",
    "#Count: Order reads by name so that the BAM file can be processed by htseq-count\n",
    "input:\n",
    "    accepted_hits\n",
    "\n",
    "output:\n",
    "    '${alignment_out}/${samplename}-sorted_by_id.bam'\n",
    "\n",
    "task:\n",
    "run:\n",
    "    java -Xmx16g -Xms512m   \\\n",
    "        -Djava.io.tmpdir=${temp_dir}  \\\n",
    "        -jar ${picard_path}/SortSam.jar  \\\n",
    "        input=${input}  \\\n",
    "        OUTPUT=${alignment_out}/${samplename}-sorted_by_id.bam  \\\n",
    "        SO=queryname   \\\n",
    "        MAX_RECORDS_IN_RAM=1000000   \\\n",
    "        TMP_DIR=${temp_dir}  \\\n",
    "        VALIDATION_STRINGENCY=SILENT\n",
    "\n",
    "\n",
    "[human_hg19_610 (htseq-count)]\n",
    "# Running htseq-count to count reads for genes. This step uses the union\n",
    "#    intersection mode, and a gene definition file with chromosome name added to gene_id.\n",
    "input:\n",
    "    sorted_bam\n",
    "\n",
    "output:\n",
    "    '${count_out}/${samplename}-gene_counts.tsv'\n",
    "\n",
    "# We cannot use --order=pos because htseq-count would fail with an error message \n",
    "run:\n",
    "    htseq-count --stranded=no --format=bam --type=exon \\\n",
    "     --mode=union ${input} ${genes_with_chr_gtf} \\\n",
    "     > ${count_out}/${samplename}-gene_counts.tsv\n",
    "\n",
    "\n",
    "[get_genesize: provides=genesize_txt]\n",
    "#    Genes.gtf file in the format of\n",
    "#\n",
    "#    chr1    unknown    exon    17233    17368    .    -    .    gene_id \"WASH7P\"; gene_name \"WASH7P\"; transcript_id \"NR_024540\"; tss_id \"TSS8151\";\n",
    "#    chr1    unknown    exon    17369    17436    .    -    .    gene_id \"MIR6859-2\"; gene_name \"MIR6859-2\"; transcript_id \"NR_107062\"; tss_id \"TSS24460\";\n",
    "#    chr1    unknown    exon    17369    17436    .    -    .    gene_id \"MIR6859-1\"; gene_name \"MIR6859-1\"; transcript_id \"NR_106918_2\"; tss_id \"TSS24460\";\n",
    "#\n",
    "# output (string):\n",
    "#    A text file in the format of\n",
    "#\n",
    "#    chr1  MIR6859-2  112324\n",
    "input:\n",
    "    genes_gtf\n",
    "\n",
    "\n",
    "python:\n",
    "\n",
    "    import sys\n",
    "    def _size(features):\n",
    "        # this is definitely not efficient but we do not really care because it will be run\n",
    "        # only once. \n",
    "        bases = set()\n",
    "        for feature in features:\n",
    "            # Add 1 because GTF input is one based\n",
    "            bases.update(range(int(feature[0]), int(feature[1]) + 1))\n",
    "        return len(bases)\n",
    "\n",
    "    # only work on selected chromosomes\n",
    "    allowed_chromosomes = set([str(x) for x in range(25)] + ['chr{}'.format(x) for x in range(25)] + \\\n",
    "                ['X', 'Y', 'M', 'chrX', 'chrY', 'chrM'])\n",
    " \n",
    "    gene_size = {}\n",
    "    with open(input[0], 'rU') as ifile:\n",
    "        for line in ifile:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            ls = line.strip().split('\\t')\n",
    "            #\n",
    "            # ls[0]: seqname (chromosome name)\n",
    "            # ls[1]: source (--ignored--)\n",
    "            # ls[2]: feature (exon only)\n",
    "            # ls[3]: start position (1-based)\n",
    "            # ls[4]: end position (1-based)\n",
    "            # ls[5]: score (--ignored---)\n",
    "            # ls[6]: strand (--ignored--)\n",
    "            # ls[7]: frame (--ignored--)\n",
    "            # ls[8]: attributes, look for gene_id\n",
    "            #\n",
    "            if ls[0] not in allowwd_chromosomes:\n",
    "                continue\n",
    "            if len(ls) < 5:\n",
    "                continue\n",
    "            if ls[2] != 'exon':\n",
    "                continue\n",
    "            try:\n",
    "                gene_id = [x.strip().rsplit(' ', 1)[-1].strip('\"').strip(\"'\") for x in ls[8].split(';') if x.strip().startswith('gene_id')]\n",
    "            except Exception as e:\n",
    "                sys.stderr.write('Failed to parse {}: {}'.format(line, e))\n",
    "                continue\n",
    "            #\n",
    "            if not gene_id:\n",
    "                sys.stderr.write('No gene_id for record {}'.format(line))\n",
    "            #\n",
    "            # use gene_id.chr as key\n",
    "            try:\n",
    "                key = gene_id[0] + '.' + ls[0]\n",
    "                if key in gene_size:\n",
    "                    if (int(ls[3]), int(ls[4])) != gene_size[key][3][-1]:\n",
    "                        gene_size[key][1] = min(gene_size[key][1], int(ls[3]))\n",
    "                        gene_size[key][2] = max(gene_size[key][2], int(ls[4]))\n",
    "                        gene_size[key][3].append((int(ls[3]), int(ls[4])))\n",
    "                else:\n",
    "                    gene_size[key] = [ls[0], int(ls[3]), int(ls[4]), [(int(ls[3]), int(ls[4]))]]\n",
    "            except Exception as e:\n",
    "                sys.stderr.write('Failed to store key {}: {}'.format(key, e))\n",
    "                continue\n",
    "    #\n",
    "    with open(${output!r}, 'w') as ofile:\n",
    "        for key in sorted(gene_size.keys()):\n",
    "            val = gene_size[key]\n",
    "            #\n",
    "            # Remove chr from key for output\n",
    "            ofile.write('{0}\\t{1}\\t{2}\\t{3}\\t{4}\\n'.format(val[0], key[:-len(val[0])-1], val[1], val[2], \n",
    "                _size(val[3])))\n",
    "\n",
    "\n",
    "[flagstat: provides='{filename}.bam.flagstat']\n",
    "# Alignment (samtools): Generating statistics of aligned reads.\n",
    "input:\n",
    "    '${filename}.bam'\n",
    "\n",
    "run:\n",
    "    samtools flagstat ${input} > ${input}.flagstat\n",
    " \n",
    "## # format of flagstat file. \n",
    "## # \n",
    "## #2181882 + 0 in total (QC-passed reads + QC-failed reads)\n",
    "## #0 + 0 duplicates\n",
    "## #2181882 + 0 mapped (100.00%:nan%)\n",
    "## #2181882 + 0 paired in sequencing\n",
    "## #mapped_reads = ${eval([line.split('m')[0] for line in open(input[0] + '.flagstat').read().split('\\n') if 'mapped' in line][0])}\n",
    "## \n",
    "\n",
    "[mapped_reads: shared='mapped_reads']\n",
    "input:\n",
    "    '${accepted_hits}.flagstat'\n",
    "\n",
    "depends:\n",
    "    sos_variable('accepted_hits')\n",
    "\n",
    "with open(input[0]) as flgs:\n",
    "    for line in flgs:\n",
    "        if 'mapped' in line:\n",
    "            mapped_reads = eval(line.split('m')[0])\n",
    "            break\n",
    "\n",
    "\n",
    "[human_hg19_620 (Gene Count RPKM)]\n",
    "\n",
    "input:\n",
    "     '${count_out}/${samplename}-gene_counts.tsv'\n",
    "\n",
    "depends: \n",
    "    genesize_txt,\n",
    "    sos_variable('mapped_reads')\n",
    "\n",
    "output:\n",
    "    \"${count_out}/${samplename}-gene_counts_rpkm.xls\"\n",
    "\n",
    "python:\n",
    "    import sys\n",
    "    gene_size = {}\n",
    "    ambiguous_size = set()\n",
    "    with open(${depends[0]!r}) as genesize:\n",
    "        for line in genesize:\n",
    "            chr, gene, start, stop, size = line.split('\\t')\n",
    "            if gene in gene_size and gene_size[gene][3] != int(size):\n",
    "                ambiguous_size.add(gene)\n",
    "            gene_size[gene] = (chr, start, stop, int(size))\n",
    "            gene_size[gene + '.' + chr] = (chr, start, stop, int(size))\n",
    "    #\n",
    "    print('Size of {} genes imported.'.format(len(gene_size)/2))\n",
    "    with open(${input!r}) as counts, open(${output!r}, 'w') as output:\n",
    "        output.write('Chr\\tGeneID\\tStart\\tStop\\tCodingLength\\tReadCount\\tRPKM\\n')\n",
    "        for line in counts:\n",
    "            # '__no_feature', '__ambiguous', '__too_low_aQual', 'not_aligned', '__alignment_not_unique'\n",
    "            if line.startswith('__'):\n",
    "                continue\n",
    "            try:\n",
    "                gene, value = line.split('\\t', 1)\n",
    "            except:\n",
    "                sys.stderr.write('Unprocess line: {}'.format(line))\n",
    "            if not gene.strip():\n",
    "                continue\n",
    "            elif gene not in gene_size:\n",
    "                sys.stderr.write('Unknown size of gene {}'.format(gene))\n",
    "                output.write('NA\\t{}\\tNA\\tNA\\tNA\\t{}\\tNA\\n'.format(gene, value.strip()))\n",
    "            else:\n",
    "                if gene in ambiguous_size:\n",
    "                    sys.stderr.write('{} appear in different chromosomes. Its RPKM value is based on the size of one of them'.format(gene))\n",
    "                output.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{:.2f}\\n'\n",
    "                    .format(gene_size[gene][0],\n",
    "                        # output gene name if the genename was appended with chromosome name\n",
    "                        gene[:-len(gene_size[gene][0])-1] if gene.endswith('.' + gene_size[gene][0]) else gene,\n",
    "                        gene_size[gene][1],\n",
    "                        gene_size[gene][2], gene_size[gene][3], value.strip(),\n",
    "                        1.e9*int(value)/(${mapped_reads} * gene_size[gene][3])))\n",
    "\n",
    "[human_hg19_630]\n",
    "#Count: Running bedtools interectBed to get exon count.\n",
    "#Count: Calculate RPKM for exon counts.\n",
    "input:\n",
    "    sorted_bam\n",
    "\n",
    "output:\n",
    "    '${count_out}/${samplename}-exon_counts.tsv'\n",
    "\n",
    "run:\n",
    "    coverageBed -abam ${input} -b ${genes_exon_bed}  \\\n",
    "        > ${count_out}/${samplename}-exon_counts.tsv\n",
    "\n",
    "[human_hg19_631]\n",
    "\n",
    "output:\n",
    "    \"${count_out}/${samplename}-exon_counts_rpkm.xls\"\n",
    "    \n",
    "depends:\n",
    "    sos_variable('mapped_reads')\n",
    "\n",
    "python:\n",
    "    import sys\n",
    "    from collections import defaultdict\n",
    "\n",
    "    exon_counts = defaultdict(int)\n",
    "    with open(${input!r}) as counts:\n",
    "        for line in counts:\n",
    "            fields = line.split()\n",
    "            if len(fields) == 16:\n",
    "                exon_counts[tuple(fields[12:16])] += 1\n",
    "            elif len(fields) == 8:\n",
    "                if int(fields[4]) != 0:\n",
    "                    exon_counts[tuple(fields[0:4])] = int(fields[4])\n",
    "            else:\n",
    "                sys.stderr.write('Incorrect input line: {}'.format(line))\n",
    "                continue\n",
    "    sys.stderr.write('Writing counts for {} exons'.format(len(exon_counts)))\n",
    "    with open(${output!r}, 'w') as output:\n",
    "        output.write('Chr\\tStart\\tStop\\tExon\\tReadCount\\tRPKM\\n')\n",
    "        for exon in sorted(exon_counts.keys(), key=lambda x: x[3]):\n",
    "            count = exon_counts[exon]\n",
    "            # the input files are in BED format with 0-based start position\n",
    "            # we need to add 1 to the start position for consistency\n",
    "            output.write('{}\\t{}\\t{}\\t{}\\t{}\\t{:.2f}\\n'\n",
    "                .format(exon[0], int(exon[1]) + 1, exon[2], exon[3], count,\n",
    "                        1.e9*count/(${mapped_reads} * (int(exon[2]) - int(exon[1])))))\n",
    "\n",
    "\n",
    "\n",
    "[update_blast: provides='${ncbi_resource_dir}/blast/db/human_genomic.nal']\n",
    "#Resource: Download NCBI Blast databases and link the directory\n",
    "# to output dir for blast to work\n",
    "depends:\n",
    "    executable('update_blastdb.pl')\n",
    "\n",
    "output:\n",
    "    '${ncbi_resource_dir}/blast/db/human_genomic.nal',\n",
    "    '${ncbi_resource_dir}/blast/db/nt.nal'\n",
    "\n",
    "task:\n",
    "\n",
    "sh: workdir='${ncbi_resource_dir}/blast/db'\n",
    "    update_blastdb.pl human_genomic --decompress || true\n",
    "    update_blastdb.pl nt --decompress || true\n",
    "\n",
    "sh: workdir=output_dir\n",
    "    [ -d blast ] || ln -s ${ncbi_resource_dir}/blast/db blast\n",
    "\n",
    "\n",
    "[before_tophat_fusion: provides=['${output_dir}/refGene.txt', '${output_dir}/ensGene.txt']]\n",
    "#Fusion (prepare): Create an alias for tophat output directory because\n",
    "#    tophat-fusion-post require the directory to have name tophat-XXX\n",
    "#Fusion (prepare): Link refGene.txt and ensGene.txt to output directory to be used by tophat-fusion-post.\n",
    "\n",
    "depends:\n",
    "    refgene_txt, ensgene_txt\n",
    "\n",
    "run:    workdir=output_dir\n",
    "    [ -f refGene.txt ] || ln -s ${refgene_txt} refGene.txt\n",
    "    [ -f ensGene.txt ] || ln -s ${ensgene_txt} ensGene.txt\n",
    "\n",
    "stop_if(alignment_out.rstrip('/').rsplit('/', 1)[-1].startswith('tophat_') \\\n",
    "    or os.path.isdir(output_dir + '/tophat_' + alignment_out.rsplit(\"/\",1)[-1]))\n",
    "\n",
    "run:    workdir=output_dir\n",
    "    ln -s ${alignment_out.rstrip(\"/\").rsplit(\"/\",1)[-1]} ${'tophat_' + alignment_out.rsplit(\"/\",1)[-1]}\n",
    "\n",
    "\n",
    "[human_hg19_710]\n",
    "# tophat-fusion for fusion detection\n",
    "output:\n",
    "    \"${fusion_out}/potential_fusion.txt\"\n",
    "\n",
    "depends:\n",
    "    '${output_dir}/refGene.txt',\n",
    "    '${output_dir}/ensGene.txt',\n",
    "    '${ncbi_resource_dir}/blast/db/human_genomic.nal'\n",
    "\n",
    "run: workdir=output_dir\n",
    "\n",
    "    tophat-fusion-post -p 3  -o ${fusion_out.rstrip(\"/\").rsplit(\"/\")[-1]} \\\n",
    "        ${reference_dir}/BowtieIndex/genome\n",
    "\n",
    "\n",
    "[human_hg19_730]\n",
    "# (Oncofuse): filter fusion candidates using Oncofuse\n",
    "\n",
    "output:\n",
    "    '${fusion_out}/fusions_oncofuse.xls'\n",
    "\n",
    "run:\n",
    "    java -Xmx1G -jar ${oncofuse_path}/Oncofuse.jar \\\n",
    "        ${input} tophat-post AVG ${fusion_out}/fusions_oncofuse.xls\n",
    "\n",
    "[download_gatk: provides=gatk_resource_dir + '/dbsnp_138.hg19.vcf']\n",
    "download: dest_dir=gatk_resource_dir\n",
    "    ${gatk_url}/1000G_omni2.5.hg19.sites.vcf.gz\n",
    "    ${gatk_url}/1000G_omni2.5.hg19.sites.vcf.gz.md5\n",
    "    ${gatk_url}/1000G_omni2.5.hg19.sites.vcf.idx.gz\n",
    "    ${gatk_url}/1000G_omni2.5.hg19.sites.vcf.idx.gz.md5\n",
    "    ${gatk_url}/dbsnp_138.hg19.vcf.gz\n",
    "    ${gatk_url}/dbsnp_138.hg19.vcf.gz.md5\n",
    "    ${gatk_url}/dbsnp_138.hg19.vcf.idx.gz\n",
    "    ${gatk_url}/dbsnp_138.hg19.vcf.idx.gz.md5\n",
    "    ${gatk_url}/hapmap_3.3.hg19.sites.vcf.gz\n",
    "    ${gatk_url}/hapmap_3.3.hg19.sites.vcf.gz.md5\n",
    "    ${gatk_url}/hapmap_3.3.hg19.sites.vcf.idx.gz\n",
    "    ${gatk_url}/hapmap_3.3.hg19.sites.vcf.idx.gz.md5\n",
    "\n",
    "[human_hg19_800 (GATK UnifiedGenotyper)]\n",
    "# Use GATK UnifiedGenotyper caller to call variants\n",
    "input:\n",
    "    sorted_unique\n",
    "\n",
    "depends:\n",
    "    '${input}.bai',\n",
    "    sos_variable('mapped_reads')\n",
    "\n",
    "# An option -L can be used to limit the variant call to targeted regions\n",
    "# -L $ref_dir/hg19.master.gene.bed \n",
    "\n",
    "output:\n",
    "    '${variant_out}/${samplename}-gatk.vcf'\n",
    "\n",
    "run:\n",
    "    java -Xmx16g -Xms512m -Djava.io.tmpdir=${temp_dir}  \\\n",
    "        -jar ${gatk_path}/GenomeAnalysisTK.jar   \\\n",
    "        -R ${reference_dir}/WholeGenomeFasta/genome.fa   \\\n",
    "        --filter_reads_with_N_cigar   \\\n",
    "        -T UnifiedGenotyper   \\\n",
    "        -I ${input}  \\\n",
    "        --out ${variant_out}/${samplename}-gatk.vcf  \n",
    "\n",
    "[human_hg19_810 (Recalibrate Variants)]\n",
    "# recalibrate and filter variants\n",
    "output:\n",
    "    '${variant_out}/${samplename}-filter.vcf'\n",
    "\n",
    "depends:\n",
    "    '${reference_dir}/WholeGenomeFasta/genome.fa',\n",
    "    '${gatk_resource_dir}/hapmap_3.3.hg19.sites.vcf',\n",
    "    '${gatk_resource_dir}/1000G_omni2.5.hg19.sites.vcf',\n",
    "    '${gatk_resource_dir}/dbsnp_138.hg19.vcf'\n",
    "\n",
    "run:\n",
    "    java -Xmx16g -Xms512m  \\\n",
    "        -Djava.io.tmpdir=${temp_dir}  \\\n",
    "        -jar ${gatk_path}/GenomeAnalysisTK.jar   \\\n",
    "        -R ${reference_dir}/WholeGenomeFasta/genome.fa   \\\n",
    "        -T VariantRecalibrator  \\\n",
    "        -mode SNP   \\\n",
    "        -input ${input}  \\\n",
    "        -resource:hapmap,known=false,training=true,truth=true,prior=15.0 ${gatk_resource_dir}/hapmap_3.3.hg19.sites.vcf  \\\n",
    "        -resource:omni,known=false,training=true,truth=false,prior=12.0  ${gatk_resource_dir}/1000G_omni2.5.hg19.sites.vcf  \\\n",
    "        -resource:dbsnp,known=true,training=false,truth=false,prior=2.0  ${gatk_resource_dir}/dbsnp_138.hg19.vcf  \\\n",
    "        -an ReadPosRankSum -an FS   \\\n",
    "        -recalFile ${variant_out}/${samplename}.recal   \\\n",
    "        -tranchesFile ${variant_out}/${samplename}.tranches   \\\n",
    "        --maxGaussians ${4 if mapped_reads > 4000000 else 2} || true  \\\n",
    "\n",
    "if os.path.getsize('${variant_out}/${samplename}.recal') > 0:\n",
    "    run(r'''\n",
    "        java -Xmx16g -Xms512m   \\\n",
    "            -Djava.io.tmpdir=${temp_dir}   \\\n",
    "            -jar ${gatk_path}/GenomeAnalysisTK.jar   \\\n",
    "            -R ${reference_dir}/WholeGenomeFasta/genome.fa  \\\n",
    "            -T ApplyRecalibration   \\\n",
    "            -mode SNP   \\\n",
    "            -input ${input}   \\\n",
    "            -recalFile ${variant_out}/${samplename}.recal  \\\n",
    "            -tranchesFile ${variant_out}/${samplename}.tranches  \\\n",
    "            -o ${variant_out}/${samplename}-filter.vcf   \\\n",
    "            --ts_filter_level 99.0\n",
    "    ''')\n",
    "else:\n",
    "    run(r'''\n",
    "        java -Xmx16g -Xms512m  \\\n",
    "            -Djava.io.tmpdir=${temp_dir}  \\\n",
    "            -jar ${gatk_path}/GenomeAnalysisTK.jar  \\\n",
    "            -R ${reference_dir}/WholeGenomeFasta/genome.fa  \\\n",
    "            -V ${input}  \\\n",
    "            -l INFO -T VariantFiltration  \\\n",
    "            --filterExpression \"FS > 20.0\" --filterName FSFilter  \\\n",
    "            --filterExpression \"ED > 5\" --filterName EDFilter  \\\n",
    "            --filterExpression \"ReadPosRankSum < -8.0\" --filterName RPRSFilter  \\\n",
    "            --filterExpression \"ReadPosRankSum > -8.0\" --filterName RPRSFilter  \\\n",
    "            -o ${variant_out}/${samplename}-filter.vcf\n",
    "    ''')\n",
    "\n",
    "[human_hg19_900]\n",
    "#RSeQC: Generate JPEG versions of the RSeQC plots to be embedded in final report \n",
    "input:\n",
    "    rseqc_pdf\n",
    "\n",
    "output:\n",
    "    '${alignmentqc_out}/${samplename}.geneBodyCoverage.curves.jpg',\n",
    "    '${alignmentqc_out}/${samplename}.junctionSaturation_plot.jpg',\n",
    "    '${alignmentqc_out}/${samplename}.splice_events.jpg',\n",
    "    '${alignmentqc_out}/${samplename}.splice_junction.jpg',\n",
    "    '${alignmentqc_out}/${samplename}.inner_distance_plot.jpg',\n",
    "    '${alignmentqc_out}//${samplename}.DupRate_plot.jpg'\n",
    "\n",
    "# we need to wait the completion of geneBody_coverage\n",
    "run:\n",
    "    cat ${' '.join([os.path.join(alignmentqc_out, x) for x in os.listdir(alignmentqc_out) if x.endswith('.r')])}  \\\n",
    "    | sed 's/pdf(\\(.*\\).pdf\\(.\\)/jpeg(\\1.jpg\\2, width=600, height=600/' | R --no-save\n",
    "\n",
    "\n",
    "[human_hg19_120: shared='read_length']\n",
    "\n",
    "input:\n",
    "   fastq_files\n",
    "\n",
    "import gzip\n",
    "with gzip.open(input[0], 'rb') if input[0].endswith('.gz') else open(input[0], 'rb') as fastq:\n",
    "    # skip the first line\n",
    "    count = 0\n",
    "    total_length = 0\n",
    "    for index,line in enumerate(fastq):\n",
    "        if index % 4 == 1:\n",
    "            # get the second line\n",
    "            total_length += len(line.decode().strip())\n",
    "            count += 1\n",
    "        if count == 100:\n",
    "            break\n",
    "    read_length = total_length / count\n",
    "\n",
    "\n",
    "\n",
    "[alignment_summary: shared=('total_reads', 'used_reads', 'mapped_reads_perc', 'uniq_mapped_reads', 'uniq_mapped_reads_perc', 'mapped_pairs', 'mapped_pairs_perc', 'concordant_mapped_pairs', 'concordant_mapped_pairs_perc', 'genome_mapped_count', 'genome_mapped_perc', 'junction_mapped_count', 'junction_mapped_perc')]\n",
    "\n",
    "depends:\n",
    "    sos_variable('accepted_hits')\n",
    "\n",
    "with open('${alignment_out}/prep_reads.info') as prep_reads:\n",
    "    total_reads = 0\n",
    "    used_reads = 0\n",
    "    for line in prep_reads:\n",
    "        if 'reads_in' in line:\n",
    "            total_reads += int(line.split('=')[-1])\n",
    "        if 'reads_out' in line:\n",
    "            used_reads += int(line.split('=')[-1])\n",
    "#\n",
    "# get mapped reads from align_summary.txt\n",
    "with open('${alignment_out}/align_summary.txt') as align_summary:\n",
    "    uniq_mapped_reads = 0\n",
    "    uniq_mapped_pairs = 0\n",
    "    mapped_reads = 0\n",
    "    mapped_pairs = 0\n",
    "    concordant_mapped_pairs = 0\n",
    "    for idx, line in enumerate(align_summary):\n",
    "        if idx in (2, 6):\n",
    "            #  Mapped   :    770754 (77.1% of input)\n",
    "            mapped_reads += int(line.split(':')[1].split('(')[0].strip())\n",
    "        if idx == 10:\n",
    "            # Aligned pairs:\n",
    "            mapped_pairs += int(line.split(':')[1].strip())\n",
    "        if idx in (3, 7):\n",
    "            uniq_mapped_reads += int(line.split(':')[1].split('(')[0].strip())\n",
    "        if idx == 12:\n",
    "            concordant_mapped_pairs = int(line.split()[0])\n",
    "    uniq_mapped_reads = mapped_reads - uniq_mapped_reads\n",
    "    uniq_mapped_reads_perc = uniq_mapped_reads * 100. / total_reads\n",
    "    mapped_reads_perc = mapped_reads * 100. / total_reads\n",
    "    concordant_mapped_pairs = mapped_pairs - concordant_mapped_pairs\n",
    "    concordant_mapped_pairs_perc = concordant_mapped_pairs * 200.0 / total_reads\n",
    "    mapped_pairs_perc = mapped_pairs * 200.0 / total_reads\n",
    "\n",
    "# get junction reads\n",
    "with open('${alignment_out}/junction.count') as junction_count:\n",
    "    junction_mapped_count = int(junction_count.readline().strip())\n",
    "    genome_mapped_count = mapped_reads - junction_mapped_count\n",
    "    junction_mapped_perc = junction_mapped_count * 100. / total_reads\n",
    "    genome_mapped_perc = genome_mapped_count * 100. / total_reads\n",
    "\n",
    "uniq_mapped_reads = mapped_reads - uniq_mapped_reads\n",
    "uniq_mapped_reads_perc = uniq_mapped_reads * 100. / total_reads\n",
    "mapped_reads_perc = mapped_reads * 100. / total_reads\n",
    "concordant_mapped_pairs = mapped_pairs - concordant_mapped_pairs\n",
    "concordant_mapped_pairs_perc = concordant_mapped_pairs * 200.0 / total_reads\n",
    "mapped_pairs_perc = mapped_pairs * 200.0 / total_reads\n",
    "genome_mapped_count = mapped_reads - junction_mapped_count\n",
    "junction_mapped_perc = junction_mapped_count * 100. / total_reads\n",
    "genome_mapped_perc = genome_mapped_count * 100. / total_reads\n",
    "\n",
    "\n",
    "[mean_depth: shared='mean_depth']\n",
    "\n",
    "input:\n",
    "    '${count_out}/${samplename}-exon_counts_rpkm.xls'\n",
    "\n",
    "depends:\n",
    "    sos_variable('read_length')\n",
    "\n",
    "mean_depth = 0\n",
    "with open(input[0]) as exons:\n",
    "    exons.readline()\n",
    "    total_reads = 0\n",
    "    total_length = 0\n",
    "    for line in exons:\n",
    "        chr, start, end, name, count, rpkm = line.split()\n",
    "        if int(count) < 2:\n",
    "            continue\n",
    "        total_reads += int(count)\n",
    "        total_length += int(end) - int(start) + 1\n",
    "    mean_depth = float(total_reads) * int(read_length) / total_length\n",
    "\n",
    "\n",
    "[get_counts: shared=('num_genes', 'num_covered_genes', 'num_exons', 'num_variants', 'num_valid_variants', 'num_oncofuse_fusions')]\n",
    "\n",
    "depends:\n",
    "    '${count_out}/${samplename}-gene_counts_rpkm.xls',\n",
    "    '${count_out}/${samplename}-exon_counts_rpkm.xls',\n",
    "    '${fusion_out}/fusions_oncofuse.xls',\n",
    "    '${variant_out}/${samplename}-filter.vcf'\n",
    "\n",
    "def _lineCount(filename, matching=None):\n",
    "    count = 0\n",
    "    count_no_comment = 0\n",
    "    count_matching = 0\n",
    "    with open(filename, 'r') as ifile:\n",
    "        for line in ifile:\n",
    "            count += 1\n",
    "            if not line.startswith('#'):\n",
    "                count_no_comment += 1\n",
    "            if matching is not None:\n",
    "                try:\n",
    "                    if line.split()[matching[0]].strip() == matching[1]:\n",
    "                        count_matching += 1\n",
    "                except:\n",
    "                    pass\n",
    "    return count, count_no_comment, count_matching\n",
    "\n",
    "gene_count = _lineCount('${count_out}/${samplename}-gene_counts_rpkm.xls', matching=(5, '0'))\n",
    "num_genes = gene_count[0] - 1\n",
    "# all lines - 0 count\n",
    "num_covered_genes = gene_count[0] - gene_count[2] - 1\n",
    "num_exons = _lineCount('${count_out}/${samplename}-exon_counts_rpkm.xls')[0] - 1\n",
    "\n",
    "num_oncofuse_fusions = _lineCount('${fusion_out}/fusions_oncofuse.xls')[0] - 1\n",
    "variant_count = _lineCount('${variant_out}/${samplename}-filter.vcf', matching=(6, 'PASS'))\n",
    "\n",
    "num_variants = variant_count[1]\n",
    "num_valid_variants = variant_count[2]\n",
    "\n",
    "[human_hg19_910]\n",
    "#Summary: Write summary.html to report all results.\n",
    "\n",
    "output:\n",
    "    '${output_dir}/summary.html'\n",
    "\n",
    "depends:\n",
    "    [sos_variable(x) for x in (\n",
    "        'read_length',\n",
    "        'mean_depth',\n",
    "        'mate_inner_dist',\n",
    "        'mate_std_dev',\n",
    "        'total_reads',\n",
    "        'used_reads',\n",
    "        'mapped_reads',\n",
    "        'mapped_reads_perc',\n",
    "        'uniq_mapped_reads',\n",
    "        'uniq_mapped_reads_perc',\n",
    "        'mapped_pairs',\n",
    "        'mapped_pairs_perc',\n",
    "        'concordant_mapped_pairs',\n",
    "        'concordant_mapped_pairs_perc',\n",
    "        'genome_mapped_count',\n",
    "        'genome_mapped_perc',\n",
    "        'junction_mapped_count',\n",
    "        'junction_mapped_perc',\n",
    "        'reference_genes',\n",
    "        'reference_genome',\n",
    "        'num_genes',\n",
    "        'num_covered_genes',\n",
    "        'num_exons',\n",
    "        'num_variants',\n",
    "        'num_valid_variants',\n",
    "        'num_oncofuse_fusions')]\n",
    "\n",
    "parameter: css = 'default.css'\n",
    "\n",
    "if not os.path.isfile(css):\n",
    "    logger.warning('{} does not exist. No CSS is used in HTML output'.format(css))\n",
    "    css_style = ''\n",
    "else:\n",
    "    with open(css) as style:\n",
    "        css_style = style.read()\n",
    "\n",
    "with open(output[0], 'w') as summary:\n",
    "    summary.write(r'''\n",
    "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\">\n",
    "<html>\n",
    "<head>\n",
    "  <meta content=\"text/html; charset=ISO-8859-1\"\n",
    "    http-equiv=\"content-type\">\n",
    "  <title>${samplename}</title>\n",
    " <style type=\"text/css\">\n",
    " ${css_style}\n",
    " </style>\n",
    "</head>\n",
    "<body>\n",
    "<h1>RNA Seq analysis for sample ${samplename}</h1>\n",
    "<p>Generated by pipeline ${pipeline_name} ${pipeline_version}</p>\n",
    "\n",
    "<h2>Project description</h2>\n",
    "\n",
    "The goal of the analysis is to evaluate how well RNA Seq sequencing worked on the sample,\n",
    "obtain gene and exon expression, fusion candidates, and variant calls from the sample.\n",
    "\n",
    "<h3>Basic information</h3>\n",
    "\n",
    "<table class=\"gridtable\">\n",
    "<tr>\n",
    "<th>Sample name</th><td>${samplename}</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>Type</th><td>Paired ends</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>Read length</th><td>${read_length}</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>Mean Depth of Coverage <sup>*</sup></th><td>${mean_depth:.1f} </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<th>Inner distance between paired reads<sup>**</sup></th><td>${mate_inner_dist} (stdev=${mate_std_dev})</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<p>* The mean depth of coverage is roughly estimated by number of mapped reads times read length and divided by the total length of exons. \n",
    "A low depth of coverage might appear if the mapping rate is low.</p>\n",
    "<p>** Mean and standard deviation of inner distance is estimated by distances between 1M pairs of aligned reads.</p>\n",
    "\n",
    "<h2>Result summary</h2>\n",
    "\n",
    "<h3>Read QC -- FastQC report</h3>\n",
    "<p><a href=\"http://www.bioinformatics.babraham.ac.uk/projects/fastqc/\">FastQC</a> is a quality control tool for high throughput sequence data. \n",
    "Please check <a href=\"http://www.bioinformatics.babraham.ac.uk/projects/fastqc/Help/3%20Analysis%20Modules/\">here</a> for details of each plot.\n",
    "Note that it is normal for RNA Seq samples to have high duplication level and uneven distribution of Kmer content. Warnings \n",
    "on items such GC content distribution are more alarming.</p>\n",
    "\n",
    "<table class=\"gridtable\">\n",
    "<tr>\n",
    "<tr><th>Per base sequence quality</th><th>Per base sequence content</th><th>Per sequence GC content</th></tr>\n",
    "<tr>\n",
    "    <td>\n",
    "    <a href=\"../${readqc_out}/${samplename}_fastqc.html#M1\">\n",
    "    <IMG SRC=\"../${readqc_out}/per_base_quality.png\" WIDTH=300 ALT=\"Per base sequence quality\">\n",
    "    </a></td>\n",
    "    <td>\n",
    "     <a href=\"../${readqc_out}/${samplename}_fastqc.html#M4\">\n",
    "    <IMG SRC=\"../${readqc_out}/per_base_sequence_content.png\" WIDTH=300 ALT=\"Per base sequence content\">\n",
    "    </a></td>\n",
    "    <td>\n",
    "    <a href=\"../${readqc_out}/${samplename}_fastqc.html#M5\">\n",
    "    <IMG SRC=\"../${readqc_out}/per_sequence_gc_content.png\" WIDTH=300 ALT=\"Per sequence GC content\">\n",
    "    </a></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<p><a href=\"../${readqc_out}/${samplename}_fastqc.html\">Complete FastQC reports</a> </p>\n",
    "\n",
    "<h3>Alignment summary</h3>\n",
    "<p>Input reads are aligned to the transcriptome of ${reference_genes} genes using reference genome ${reference_genome}.\n",
    "The mapping rate might appear higher if the reads are mapped to the whole genome.</p>\n",
    "\n",
    "<table class=\"gridtable\">\n",
    "<tr>\n",
    "<th>Total reads</th>\n",
    "<th>Used reads</th>\n",
    "<th>Mapped reads</th>\n",
    "<th>Uniquely mapped reads</th>\n",
    "<th>Mapped pairs</th>\n",
    "<th>Concordant mapped pairs</th>\n",
    "<th>Mapped reads (genome)</th>\n",
    "<th>Mapped reads (junction)</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>${total_reads:,}</td>\n",
    "<td>${used_reads:,}</td>\n",
    "<td>${mapped_reads:,} (${mapped_reads_perc:.1f}%)</td>\n",
    "<td>${uniq_mapped_reads:,} (${uniq_mapped_reads_perc:.1f}%)</td>\n",
    "<td>${mapped_pairs:,} (${mapped_pairs_perc:.1f}%)</td>\n",
    "<td>${concordant_mapped_pairs:,} (${concordant_mapped_pairs_perc:.1f}%)</td>\n",
    "<td>${genome_mapped_count:,} (${genome_mapped_perc:.1f}%)</td>\n",
    "<td>${junction_mapped_count:,} (${junction_mapped_perc:.1f}%)</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<h3>Alignment QC -- RSeQC plots</h3>\n",
    "<table class=\"gridtable\">\n",
    "<tr>\n",
    "<tr><th>Junction saturation</th><th>Inner distance</th><th>Splicing junction</th></tr>\n",
    "<tr>\n",
    "    <td>\n",
    "    <a href=\"../${alignmentqc_out}/${samplename}.junctionSaturation_plot.pdf\">\n",
    "    <IMG SRC=\"../${alignmentqc_out}/${samplename}.junctionSaturation_plot.jpg\" WIDTH=300 ALT=\"Junction saturation plot\">\n",
    "    </a></td>\n",
    "    <td>\n",
    "     <a href=\"../${alignmentqc_out}/${samplename}.inner_distance_plot.pdf\">\n",
    "    <IMG SRC=\"../${alignmentqc_out}/${samplename}.inner_distance_plot.jpg\" WIDTH=300 ALT=\"Inner distance plot\">\n",
    "    </a></td>\n",
    "    <td>\n",
    "    <a href=\"../${alignmentqc_out}/${samplename}.splice_junction.pdf\">\n",
    "    <IMG SRC=\"../${alignmentqc_out}/${samplename}.splice_junction.jpg\" WIDTH=300 ALT=\"Splicing junction plot\">\n",
    "    </a></td>\n",
    "</tr>\n",
    "<tr><th>Read duplication</th><th>Gene body coverage</th><th>Splicing events</th></tr>\n",
    "<tr>\n",
    "    <td>\n",
    "    <a href=\"../${alignmentqc_out}/${samplename}.DupRate_plot.pdf\">\n",
    "    <IMG SRC=\"../${alignmentqc_out}/${samplename}.DupRate_plot.jpg\" WIDTH=300 ALT=\"Read duplication plot\">\n",
    "    </a></td>\n",
    "    <td>\n",
    "    <a href=\"../${alignmentqc_out}/${samplename}.geneBodyCoverage.curves.pdf\">\n",
    "    <IMG SRC=\"../${alignmentqc_out}/${samplename}.geneBodyCoverage.curves.jpg\" WIDTH=300 ALT=\"Gene body coverage plot\">\n",
    "    </a></td>\n",
    "    <td>\n",
    "    <a href=\"../${alignmentqc_out}/${samplename}.splice_events.pdf\">\n",
    "    <IMG SRC=\"../${alignmentqc_out}/${samplename}.splice_events.jpg\" WIDTH=300 ALT=\"Splicing events plot\">\n",
    "    </a></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<h3>Gene and exon counts</h3>\n",
    "\n",
    "<ul>\n",
    "<li><a href=\"../${count_out}/${samplename}-gene_counts_rpkm.xls\">Gene counts with RPKM </a> (${num_genes:,} genes, ${num_covered_genes:,} overlap with at least 1 read)</li>\n",
    "<li><a href=\"../${count_out}/${samplename}-exon_counts_rpkm.xls\">Exon counts with RPKM </a> (${num_exons:,} exons overlapped with at least 1 read)</li>\n",
    "</ul>\n",
    "\n",
    "<p>The gene count was performed by <a href=\"http://www-huber.embl.de/HTSeq/doc/count.html\">htseq-count</a> under\n",
    "the <b>union</b> model. The exon count was performed by <a href=\"https://code.google.com/p/bedtools/\">bedtools</a>\n",
    "which counts the number of reads that overlap with each exon. These files are tab-delimited files with .xls extension.</p>\n",
    "\n",
    "<h3>Fusion candidates</h3>\n",
    "The following are fusion candidates produced by tophat-fusion:\n",
    "<ul>\n",
    "<li><a href=\"../${fusion_out}/fusions_oncofuse.xls\">Oncofuse filtered fusion candidates</a> (${num_oncofuse_fusions:,} fusions in tab-delimited file with .xls extension)</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Variant calls</h3>\n",
    "<ul>\n",
    "<li> <a href=\"../${variant_out}/${samplename}-filter.vcf\">GATK detected SNV in VCF format</a>(${num_variants:,} variants, ${num_valid_variants:,} passed basic filtering)</li>\n",
    "</ul>\n",
    "\n",
    "The variants are called using the GATK Unified Genotyper and include only Single Nucleotide Variants, no indel detection was performed.</p>\n",
    "<p>\n",
    "<p>\n",
    "</body>\n",
    "</html>\n",
    "''')\n",
    "\n",
    "[human_hg19_1000]\n",
    "#Summary: Compress all result files into a deliverable package.\n",
    "input:\n",
    "    '${output_dir}/summary.html',\n",
    "    '${readqc_out}/${samplename}_fastqc.html',\n",
    "    '${readqc_out}/per_base_quality.png',\n",
    "    '${readqc_out}/per_base_sequence_content.png',\n",
    "    '${readqc_out}/per_sequence_gc_content.png',\n",
    "    '${alignmentqc_out}/${samplename}.geneBodyCoverage.curves.pdf',\n",
    "    '${alignmentqc_out}/${samplename}.junctionSaturation_plot.pdf',\n",
    "    '${alignmentqc_out}/${samplename}.splice_events.pdf',\n",
    "    '${alignmentqc_out}/${samplename}.splice_junction.pdf',\n",
    "    '${alignmentqc_out}/${samplename}.inner_distance_plot.pdf',\n",
    "    '${alignmentqc_out}//${samplename}.DupRate_plot.pdf',\n",
    "    '${alignmentqc_out}/${samplename}.geneBodyCoverage.curves.jpg',\n",
    "    '${alignmentqc_out}/${samplename}.junctionSaturation_plot.jpg',\n",
    "    '${alignmentqc_out}/${samplename}.splice_events.jpg',\n",
    "    '${alignmentqc_out}/${samplename}.splice_junction.jpg',\n",
    "    '${alignmentqc_out}/${samplename}.inner_distance_plot.jpg',\n",
    "    '${alignmentqc_out}/${samplename}.DupRate_plot.jpg',\n",
    "    '${count_out}/${samplename}-gene_counts_rpkm.xls',\n",
    "    '${count_out}/${samplename}-exon_counts_rpkm.xls',\n",
    "    '${fusion_out}/fusions_oncofuse.xls',\n",
    "    '${variant_out}/${samplename}-filter.vcf'\n",
    "\n",
    "output:\n",
    "    '${output_dir}/${samplename}.zip'\n",
    "\n",
    "run:\n",
    "    zip ${output_dir}/${samplename}.zip ${input}\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "## Workflow to install required tools\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env sos-runner\n",
    "#fileformat=SOS1.0\n",
    "\n",
    "#\n",
    "# Auxiliary steps to install required NGS tools if it is not avaible\n",
    "#\n",
    "\n",
    "# default installation directory. This directory is recognized by\n",
    "# default by SoS so that commands installed would be immediately usable\n",
    "# by sos workflows. You can use commands such as\n",
    "#\n",
    "#    sudo sos run install_ngs install_fastqc --install-dir /usr/local/bin/\n",
    "#\n",
    "# to install programs in a different directory.\n",
    "\n",
    "parameter: install_dir  = '~/.sos/bin'\n",
    "parameter: download_dir = '~/.sos/bin/download'\n",
    "\n",
    "[install_fastqc: provides=executable('fastqc')]\n",
    "ver = 'v0.11.5'\n",
    "\n",
    "download: dest_dir=download_dir\n",
    "    http://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_${ver}.zip\n",
    "\n",
    "warn_if(os.path.isdir('${install_dir!e}/FastQC_${ver}'),\n",
    "\t\"Replacing FastQC version ${ver} under ${install_dir!e}/FastQC_${ver}.\")\n",
    "\n",
    "warn_if(os.path.isfile('${install_dir!e}/fastqc}'),\n",
    "\t\"Replacing fastqc command ${install_dir!e}/fastqc.\")\n",
    "\n",
    "run:    \n",
    "    cd ${install_dir!e} && \\\n",
    "    rm -rf ${install_dir!e}/FastQC_${ver} && \\\n",
    "\trm -f ${install_dir!e}/fastqc && \\\n",
    "    unzip -o ${download_dir!e}/fastqc_*.zip  && \\\n",
    "    mv ${install_dir!e}/FastQC ${install_dir!e}/FastQC_${ver} && \\\n",
    "    chmod 755 ${install_dir}/FastQC_${ver}/fastqc && \\\n",
    "    ln -s ${install_dir}/FastQC_${ver}/fastqc ${install_dir}\n",
    "\t\n",
    "[install_bowtie: provides=executable('bowtie')]\n",
    "download: dest_dir=download_dir\n",
    "    https://sourceforge.net/projects/bowtie-bio/files/bowtie/1.1.2/bowtie-1.1.2-macos-x86_64.zip\n",
    "\n",
    "run:    workdir=download_dir\n",
    "    unzip bowtie-1.1.2-macos-x86_64.zip && \\\n",
    "\trm -rf ${install_dir!e}/bowtie-1.1.2 && \\\n",
    "    mv bowtie-1.1.2 ${install_dir!e} && \\\n",
    "\tln -s -f ${install_dir!e}/bowtie-1.1.2/* ${install_dir!e}\n",
    "\n",
    "[install_bowtie2: provides=executable('bowtie2')]\n",
    "download: dest_dir=download_dir\n",
    "    https://sourceforge.net/projects/bowtie-bio/files/bowtie2/2.2.9/bowtie2-2.2.9-macos-x86_64.zip\n",
    "\n",
    "run:    workdir=download_dir\n",
    "    unzip bowtie2-2.2.9-macos-x86_64.zip && \\\n",
    "\trm -rf ${install_dir!e}/bowtie2-2.2.9 && \\\n",
    "    mv bowtie2-2.2.9 ${install_dir!e} && \\\n",
    "\tln -s -f ${install_dir!e}/bowtie2-2.2.9/* ${install_dir!e}\n",
    "\n",
    "\n",
    "[install_tophat2: provides=executable('tophat2')]\n",
    "# install tophat 2, which requires bowtie2\n",
    "#\n",
    "# NOTE: The pre-compiled binary does not work well under mac so it is\n",
    "# highly recommened that you compile from source. However, compiling from\n",
    "# source requires xcode and boost, and the later is not among the easiest\n",
    "# software package to install\n",
    "\n",
    "depends:  executable('bowtie2')\n",
    "\n",
    "#download: dest_dir=download_dir\n",
    "#\thttps://ccb.jhu.edu/software/tophat/downloads/tophat-2.0.13.tar.gz\n",
    "\n",
    "#run:\tworkdir=download_dir\n",
    "#\ttar zxf tophat-2.0.13.tar.gz && \\\n",
    "#\tcd tophat-2.0.13 && \\\n",
    "#\t./configure --prefix=${os.path.dirname(install_dir)!e} && \\\n",
    "#\tmake -B && make install\n",
    "\t\n",
    "download: dest_dir=download_dir\n",
    "    https://ccb.jhu.edu/software/tophat/downloads/tophat-2.0.13.OSX_x86_64.tar.gz\n",
    "\n",
    "run:    workdir=download_dir\n",
    "    tar zxf tophat-2.0.13.OSX_x86_64.tar.gz && \\\n",
    "\trm -rf ${install_dir!e}/tophat-2.0.13.OSX_x86_64 && \\\n",
    "    mv tophat-2.0.13.OSX_x86_64 ${install_dir!e} && \\\n",
    "\tln -s -f ${install_dir!e}/tophat-2.0.13.OSX_x86_64/* ${install_dir!e}\n",
    "\n",
    "\n",
    "[install_rseqc: provides=executable('inner_distance.py')]\n",
    "\n",
    "run:\n",
    "\tpip install RSeQC\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "pysos.kernel.SoS_Exporter",
   "pygments_lexer": "sos"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
