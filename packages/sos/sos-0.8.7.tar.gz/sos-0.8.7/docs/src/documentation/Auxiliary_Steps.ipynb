{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary steps and makefile-style workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliary steps are special steps that are executed to provide [targets](Understanding_Targets.html) that are required by others.\n",
    "\n",
    "For example, when the following step is executed with an input file `bamfile` (with extension `.bam`), it checks the existence of input file (`bamfile`), and a dependent index file (with extension `.bam.bai`).\n",
    "\n",
    "```sos\n",
    "[100 (call variant)]\n",
    "input:   bamfile\n",
    "depends: bamfile + '.bai'\n",
    "run:\n",
    "    # commands to call variants from \n",
    "    # input bam file\n",
    "```\n",
    "\n",
    "If the index file exists, generated either by another step or outside of SoS, sos will go ahead and execute the step. Otherwise  SoS will look in the script for a step that provides such a target, which would be similar to \n",
    "\n",
    "```sos\n",
    "[index_bam : provides='{sample}.bam.bai']\n",
    "input: \"${sample}.bam\"\n",
    "run:\n",
    "     samtools index ${input}\n",
    "```\n",
    "\n",
    "Such a step is characterized by a **`provides`** option (or a **`shared`** option that will be discussed later) and is called an auxiliary step. In this particular case, if `bamfile=\"AS123.bam\"`, the requested dependent file would be `AS123.bam.bai`. Through the matching mechanism of option `provides`, the `index_bam` step would be executed with variables `sample=\"AS123\"` and `output=[\"AS123.bam.bai\"]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An auxiliary step can trigger other auxiliary steps and form a DAG (Directed Acyclic Graph). Acutually, you can write workflows in a make-file style with all auxiliary steps and execute workflows defined by targets. If you are familiar with Makefile, especially [snakemake](https://bitbucket.org/johanneskoester/snakemake), it can be natural for you to implement your workflow in this style. The advantage of SoS is that **you can use either or both forward-style and makefile-style steps to define your workflow** and take advantages of both approaches. For example, people frequently need to create fake targets to trigger steps that do not produce any target in a makefile-style workflow system, but this is not needed in SoS because steps defined in forward-style will always be executed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step option `provides`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "An auxiliary step can be defined in the format of\n",
    "\n",
    "```sos\n",
    "[step_name : provides=pattern]\n",
    "```\n",
    "\n",
    "where `pattern` can be\n",
    "\n",
    "* A file pattern such as `\"{sample}.bam.idx\"`\n",
    "* Other types of targets such as `executable(\"ms\")`\n",
    "* A list (sequence) of one or more file patterns and targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A file pattern is a filename with optional patterns with variable names enbraced in `{ }`. SoS matches filenames with the patterns and, if successful, assign variables with matched parts of the names. \n",
    "\n",
    "The following example removes all local `*.bam` and `*.bam.bi` file before it executes three workflows defined by `targets`. We use magic `%run` to execute it, which is equivalent to executing it from command line using commands such as\n",
    "```bash\n",
    "    sos run myscript -t TS1.bam\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> compress input to TS1.bam\n"
     ]
    }
   ],
   "source": [
    "%sandbox\n",
    "%preview --off\n",
    "%run -t TS1.bam\n",
    "\n",
    "[compress: provides = '{filename}.bam']\n",
    "print(\"> ${step_name} input to ${output}\")\n",
    "sh:\n",
    "    touch ${output}\n",
    "\n",
    "[index: provides = '{filename}.bam.bai']\n",
    "input: \"${filename}.bam\"\n",
    "print(\"> ${step_name} ${input} to ${output}\")\n",
    "sh:\n",
    "    touch ${output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> compress input to TS2.bam\n",
      "> index TS2.bam to TS2.bam.bai\n"
     ]
    }
   ],
   "source": [
    "%sandbox\n",
    "%rerun -t TS2.bam.bai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As you can see from the output, when the first workflow is executed with target `TS1.bam`, step `compress` is executed to produce it. In the run, both steps are executed to generate `TS2.bam` and then `TS2.bam.bai`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step option `shared`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common task of SoS steps is to provide some information through SoS variables. This can be achived by a `provides` option with `sos_variale` targets, but can be more easily implemented with a `shared` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14 notebooks in this directory\n"
     ]
    }
   ],
   "source": [
    "# remove var in case it is defined already\n",
    "%dict --del numNotebooks\n",
    "\n",
    "# this step provides variable `numNotebooks`\n",
    "[count: shared='numNotebooks']\n",
    "import glob\n",
    "numNotebooks = len(glob.glob('*.ipynb'))\n",
    "\n",
    "[default]\n",
    "depends: sos_variable('numNotebooks')\n",
    "print(\"There are ${numNotebooks} notebooks in this directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workflow has one step that depends on a `sos_variable` `numNotebooks`. The `count` step is then executed to provide this variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing workflows with auxiliary steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can execute forward-style workflows by specifying workflow name (can be `default`) from command line. The workflow can trigger auxiliary steps for the generation of unavailable targets. The workflows are executed with a mind-setting of **apply workflow to certain input file**.\n",
    "\n",
    "You can execute a makefile-style workflow by specifying one or more targets using option `-t` (target). SoS would collect all auxiliary steps in the script and create DAGs to generate these targets. The workflows are executed with a mind-setting of **execute necessary steps to generate specified output files**. Forward-style workflows defined in the script, if defined, would be ignored.\n",
    "\n",
    "You can specify both a forward-style workflow and one or more targets using the `-t` option. In this case SoS would create a DAG with both the forward-style workflow and steps to produce the specified targets. The DAG would then be trimmed to a sub-DAG that produce only specified targets. The usage is usually used to **produce only selected targets from a forward-style workflow**. In contrast to the second case where targets have to be targets of auxiliary steps, targets specified in this case can be any output targets from the forward-style workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use a slightly complex example with both forward-style and auxiliary steps to demonstrate these three cases. In this case we are using action `sos_run` to execute workflows as multiple subworkflows, saving us the trouble to execute the script multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward-style workflow\n",
      "> Running step process_10\n",
      "> download step20.pdf\n",
      "> Running step process_20 to produce step20.out\n",
      "> Running step process_30 to produce step30.out\n",
      "\n",
      "Makefile-style workflow\n",
      "> download ms.pdf\n",
      "> gzip ms.pdf to ms.pdf.gz\n",
      "\n",
      "Targets of forward-style workflow\n",
      "> Running step process_10\n",
      "> Running step process_20 to produce step20.out\n",
      "\n",
      "Targets from forward-style and makefile-style workflows\n",
      "> download ms1.pdf\n",
      "> Running step process_10\n",
      "> Running step process_20 to produce step20.out\n",
      "> gzip ms1.pdf to ms1.pdf.gz\n",
      "\n",
      "Invalid target step20.out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to process statement print(\"Forward-style workflow\"...p20.out\"]): No step to generate target step20.out\n",
      "Sandbox execution failed."
     ]
    }
   ],
   "source": [
    "%sandbox --expect-error\n",
    "\n",
    "[gzip: provides='{name}.gz']\n",
    "input: \"${name}\"\n",
    "print(\"> ${step_name} ${input} to ${output}\")\n",
    "run:\n",
    "    touch ${output}\n",
    "\n",
    "[download: provides='{name}.pdf']\n",
    "print(\"> ${step_name} ${output}\")\n",
    "run:\n",
    "    touch ${output}\n",
    "\n",
    "[process_10]\n",
    "print(\"> Running step ${step_name}\")\n",
    "\n",
    "[process_20]\n",
    "depends: \"step20.pdf\"\n",
    "output: \"step20.out\"\n",
    "print(\"> Running step ${step_name} to produce ${output}\")\n",
    "run:\n",
    "    touch ${output}\n",
    "\n",
    "[process_30]\n",
    "output: \"step30.out\"\n",
    "print(\"> Running step ${step_name} to produce ${output}\")\n",
    "run:\n",
    "    touch ${output}\n",
    "\n",
    "[default]\n",
    "print(\"Forward-style workflow\")\n",
    "sos_run(\"process\")\n",
    "\n",
    "print(\"\\nMakefile-style workflow\")\n",
    "sos_run(targets=\"ms.pdf.gz\")\n",
    "\n",
    "print(\"\\nTargets of forward-style workflow\")\n",
    "sos_run(\"process\", targets=\"step20.out\")\n",
    "\n",
    "print(\"\\nTargets from forward-style and makefile-style workflows\")\n",
    "sos_run(\"process\", targets=[\"step20.out\", \"ms1.pdf.gz\"])\n",
    "\n",
    "os.remove('step20.out')\n",
    "print(\"\\nInvalid target step20.out\")\n",
    "sos_run(targets=[\"step20.out\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This example has a forward-style workflow `process` in which step `process_20` depends on an auxiliary step `download`.\n",
    "\n",
    "1. In the first case with command line equivalence\n",
    "\n",
    "  ```bash\n",
    "  sos run myscript process\n",
    "  ```\n",
    "  the forward-style workflow `process` is executed.\n",
    "\n",
    "2. In the second example\n",
    "  ```bash\n",
    "  sos run myscript -t ms.pdf.gz\n",
    "  ```\n",
    "  two auxiliary steps `download` and `gzip` are called to produce target `ms.pdf.gz`.\n",
    "  \n",
    "3. In the third example\n",
    "  ```bash\n",
    "  sos run myscript process -t step20.out\n",
    "  ```\n",
    "  the `process` workflow is executed partially until it generates target `step20.out`.\n",
    "  \n",
    "4. In the fourth example\n",
    "  ```bash\n",
    "  sos run myscript process -t step20.out ms1.pdf.gz\n",
    "  ```\n",
    "  the `process` workflow is executed partially to produce target `step20.out`, and two auxiliary steps are executed to produce the additional target `ms1.pdf.gz`.\n",
    "  \n",
    "5. In the last example\n",
    "  ```bash\n",
    "  sos run myscript -t step20.out\n",
    "  ```\n",
    "  SoS could not find an auxiliary step to produce target `step20.out` and exited with error. Note that SoS would not try to execute a default workflow (workflow `default` or the only forwar-style workflow defined in the script) with the presence of option `-t`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Output DAG of execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SoS allows the output of Direct Acyclic Graph in [graphviz dot format](http://www.graphviz.org/content/dot-language) of the execution of the workflow using option `-d`. DAGs would be written to standard output if the option `-d` is given without value, and to one or more files if a filename is given. An extension `.dot` would be automatically added if needed. Because of the dynamic nature of SoS, multiple DAGs could be outputted with increasing or decreasing number of nodes, resulting multiple files named `FILE.dot`, `FILE_2.dot`, etc.\n",
    "\n",
    "Let us create an example with some nodes, and execute the workflow with two targets `B2.txt` and `C2.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre><font color=\"green\">## -- Preview output --</font></pre>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre> input: \n",
       "output: B2.txt\n",
       "</pre>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre><font color=\"green\">> B2.txt (0 B):</font></pre>"
      ],
      "text/plain": [
       "\n",
       "> B2.txt (0 B):"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre><font color=\"green\">## %preview dag.dot dag_2.dot</font></pre>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre><font color=\"green\">> dag.dot (463 B):</font></pre>"
      ],
      "text/plain": [
       "\n",
       "> dag.dot (463 B):"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "> Failed to preview file dag.dot: The 'graphviz' distribution was not found and is required by the application"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre><font color=\"green\">> dag_2.dot (340 B):</font></pre>"
      ],
      "text/plain": [
       "\n",
       "> dag_2.dot (340 B):"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "> Failed to preview file dag_2.dot: The 'graphviz' distribution was not found and is required by the application"
     ]
    }
   ],
   "source": [
    "%sandbox --dir temp\n",
    "%preview dag.dot dag_2.dot\n",
    "\n",
    "!rm -f A?.txt B?.txt C?.txt\n",
    "%run  -t B2.txt C2.txt -d dag\n",
    "[A_1]\n",
    "input: 'B1.txt'\n",
    "output: 'A1.txt'\n",
    "sh:\n",
    "    touch A1.txt\n",
    "\n",
    "[A_2]\n",
    "depends:  'B2.txt'\n",
    "sh:\n",
    "    touch A2.txt\n",
    "\n",
    "[B1: provides='B1.txt']\n",
    "depends: 'B2.txt'\n",
    "sh:\n",
    "    touch B1.txt\n",
    "\n",
    "[B2: provides='B2.txt']\n",
    "depends: 'B3.txt', 'C1.txt'\n",
    "sh:\n",
    "    touch B2.txt\n",
    "\n",
    "[B3: provides='B3.txt']\n",
    "sh:\n",
    "    touch B3.txt\n",
    "\n",
    "[C1: provides='C1.txt']\n",
    "depends: 'C2.txt', 'C3.txt'\n",
    "sh:\n",
    "    touch C1.txt\n",
    "\n",
    "[C2: provides='C2.txt']\n",
    "depends: 'C4.txt'\n",
    "sh:\n",
    "    touch C2.txt\n",
    "\n",
    "[C3: provides='C3.txt']\n",
    "depends: 'C4.txt'\n",
    "sh:\n",
    "    touch C3.txt\n",
    "\n",
    "[C4: provides='C4.txt']\n",
    "sh:\n",
    "    touch C4.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `-d` option produced two `.dot` files that can be converted to png format using `dot` command (e.g. `dot dag.dot -T png > dag.png`) but here we use the `%preview` magic to display them directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might have guessed, the first DAG is the complete DAG created from the workflow, and the second DAG is the trimmed down DAG that produces targets `B2.txt` and `C2.txt`. In real world applications, the DAG might grow with additional auxiliary steps if some input or dependency files are unavailable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean up\n",
    "!rm -rf temp"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos.jupyter.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "146px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
